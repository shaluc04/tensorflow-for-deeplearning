{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08_introduction_to_nlp_in_tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPedmNlIsRxSjz5Pq1NjGMQ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kE_wc_sDEOy"
      },
      "source": [
        "# Introduction to NLP fundamentals in Tensorflow\n",
        "\n",
        "NLP has the goal of deriving information out of natural langugae (could be sequences, text or speech).\n",
        "\n",
        "Another common term for NLP problems is seuence to sequence problems (seq2seq).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOc_5Ma5D-Ld"
      },
      "source": [
        "## Check for GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXYWsBcxEDlK"
      },
      "source": [
        "# !nvidia-smi -L"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIGqHyJqEOG9"
      },
      "source": [
        "## Get helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAi0RNY1Ee_W",
        "outputId": "1591bc33-56a3-42c9-f618-ff18acc76ab5"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "# Import series of helper functions for the notebook\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-22 10:41:13--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-11-22 10:41:14 (53.3 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9N7IlrirFbRa"
      },
      "source": [
        "## Get a text dataset\n",
        "\n",
        "The dataset we're going to be using is Kaggle's introduction to NLP dataset (text samples of tweets labelled as disaster or not disaster).\n",
        "\n",
        "Dataset: https://www.kaggle.com/c/nlp-getting-started/data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZICh_MGFmRQ",
        "outputId": "b1f8e060-a34d-4e4e-e0b9-1c62923d827b"
      },
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
        "\n",
        "# unzip data\n",
        "unzip_data(\"nlp_getting_started.zip\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-22 10:41:16--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 209.85.147.128, 142.250.125.128, 142.250.136.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|209.85.147.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2021-11-22 10:41:17 (102 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05OvPk1qHXOG"
      },
      "source": [
        "## Visualizing a text dataset\n",
        "\n",
        "To visualize our text samples, we first have to read them in. One way to do so would be to use python: https://realpython.com/read-write-files-python/\n",
        "\n",
        "Another way to do this is to use pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XXfK1zL6H2nS",
        "outputId": "aef72def-5484-44bb-8617-a38868bbf3d6"
      },
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "train_df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9JqE92UVI2gg",
        "outputId": "68f7d158-0a1e-4bcd-be75-af06ee1535e0"
      },
      "source": [
        "train_df[\"text\"][10]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Three people died from the heat wave so far'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4YguOYXYJBrM",
        "outputId": "ba69b879-c237-4af5-d722-17b906fdefae"
      },
      "source": [
        "# shuffle training dataframe\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
        "train_df_shuffled.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "2644  3796  ...      1\n",
              "2227  3185  ...      0\n",
              "5448  7769  ...      1\n",
              "132    191  ...      0\n",
              "6845  9810  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3KlFVsHzJW7_",
        "outputId": "562df650-9e4b-4d60-b434-55bb50e3f8e5"
      },
      "source": [
        "train_df_shuffled[\"text\"].iloc[3]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Aftershock back to school kick off was great. I want to thank everyone for making it possible. What a great night.'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PcZgI0xcJs8A",
        "outputId": "54e67744-ba4f-4060-f606-b35dfed7b5d9"
      },
      "source": [
        "# what does the dataframe look like?\n",
        "test_df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7C2cyiUKEQH",
        "outputId": "476807c7-21c5-45ae-f77f-a94f7e006325"
      },
      "source": [
        "# how many examples of each class?\n",
        "train_df.target.value_counts()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zr9oPJQ-KPzZ",
        "outputId": "e83f5bc1-d035-4102-be87-91d82fe90c4c"
      },
      "source": [
        "# how many total samples?\n",
        "len(train_df), len(test_df)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 3263)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7YQNqtQKrt9",
        "outputId": "20e78984-ec6c-42d4-e44f-d561266bdb8f"
      },
      "source": [
        "# Let's visualize some random training examples\n",
        "import random\n",
        "\n",
        "random_index = random.randint(0, len(train_df)-5) # create random indexes not higher than the total number of samples\n",
        "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f\"Target: {target}\", \"(real disaster)\" if target> 0 else \"(not real disaster)\")\n",
        "  print(f\"Text:{text}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0 (not real disaster)\n",
            "Text:it sure made an impact on me http://t.co/GS50DdG1JY\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:@TheWesternGaz I'm sure the shop is deluged by local children wanting to buy it. Really?\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:Despite the crippling anxiety and overwhelming panic attacks I'd say I'm fairly well-adjusted.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:This sale and demolition trend near Metrotown is sure resulting in some poorly maintained apartments. #burnaby #changefortheworse\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:@thebriankrause leos ass just got metaphorically blown up again #PiperWearsThePants #charmed\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xi9TwMVHNdQw"
      },
      "source": [
        "### Split data into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuDdRHiPd8Wb"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12grFQDFeEUu"
      },
      "source": [
        "# Use train_test_split to split training data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                            test_size=0.1,\n",
        "                                                                            random_state=42)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cp4ZfX7jggl",
        "outputId": "7f8b808a-ccbb-44e7-8614-bc44a3070b19"
      },
      "source": [
        "# check the lengths\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52DT0b8VjxuY",
        "outputId": "0ec32f13-a3f5-4d73-8ba7-298b4d7f15a9"
      },
      "source": [
        "# check the first 10 samples\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6kDPLMGj7yB"
      },
      "source": [
        "## Converting text into numbers\n",
        "\n",
        "Wheb dealing with a text problem, one of the first thing we have to do is convert text to numbers.\n",
        "\n",
        "There are a few ways to do this, namely:  \n",
        "* **Tokenization** - direct mapping of a token (a token could be a word or a character) to number (text vectorization).\n",
        "* **Embedding** - create a matrix of feature vector for each token (the size of the feature vector can be defined and this embedding can be learned)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlJ-ltH2lzjN"
      },
      "source": [
        "### Text vectorization (Tokenization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "styjNcBJoTR2",
        "outputId": "10edb049-63cb-4ac6-bee0-c173eb591037"
      },
      "source": [
        "train_sentences[:5]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "       'Imagine getting flattened by Kurt Zouma',\n",
              "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "       'Somehow find you and I collide http://t.co/Ee8RpOahPk'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayYDerFyoWql"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "# # Use the default text vectorization parameters\n",
        "# text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabulary (automatically add <OOV>)\n",
        "#                                     standardize=\"lower_and_strip_punctuation\",\n",
        "#                                     split=\"whitespace\",\n",
        "#                                     ngrams=None, # creates groups of n words\n",
        "#                                     output_mode=\"int\",\n",
        "#                                     output_sequence_length=None, # how long do you want your sequences to be?\n",
        "#                                     pad_to_max_tokens=True)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "oU8wVKao95M7",
        "outputId": "4f17dd78-c4f3-4da1-c816-b353bcb5946a"
      },
      "source": [
        "train_sentences[0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'@mogacola @zamtriossu i screamed after hitting tweet'"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLTT-SQ79_P6",
        "outputId": "a9fbc65f-e916-4b30-d31a-270a15747bba"
      },
      "source": [
        "train_sentences[0].split()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@mogacola', '@zamtriossu', 'i', 'screamed', 'after', 'hitting', 'tweet']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alzHAJHi-Nga",
        "outputId": "be6042bd-9f41-4f70-bfcb-fa72798c1fc2"
      },
      "source": [
        "len(train_sentences[0].split())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3y2CHQX72qoC",
        "outputId": "51a9c9ac-e285-4933-e48e-42436064bfe8"
      },
      "source": [
        "# find the average number of tokens (words) in the training tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0wL9Elo-tM6"
      },
      "source": [
        "Average number of tokens (words) in a tweet is 15."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbugBT_L-cvx"
      },
      "source": [
        "# Setup text vectorization variables\n",
        "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
        "max_length = 15  # max length our sequences will be (e.g how many words from a tweet our model will see)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8mQKYqC_zbH"
      },
      "source": [
        "# fit the text vectorizer to training data\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLb5h0-1Abrc",
        "outputId": "0f5df8a6-f711-498b-a9df-7b6d69068fa8"
      },
      "source": [
        "# create a sample sentence and tokenize it\n",
        "sample_sentence = \"There's a flood in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACqP7GilAzMr",
        "outputId": "1e977852-470d-4999-88bc-147760defdcd"
      },
      "source": [
        "# Choose a random sentence from the training dataset and tokenize it\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n {random_sentence}\\\n",
        "        \\n\\n Vectorized version:\")\n",
        "text_vectorizer([random_sentence])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            " @ameenshaikh3 sir i just only wanted to make a point about @sureshpprabhu you made and said he is lying about bridge collapse.        \n",
            "\n",
            " Vectorized version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[   1, 1590,    8,   29,  126,  974,    5,  144,    3, 1491,   54,\n",
              "        7906,   12,  299,    7]])>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmjFmddCCrsU",
        "outputId": "bd7df1e0-bf6b-4284-cde5-ea222a445471"
      },
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()  # get all of the unique words in the our training data\n",
        "top_5_words = words_in_vocab[:5] # get the most common words \n",
        "bottom_5_words = words_in_vocab[-5:] # get the least common words\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f'5 most common words: {top_5_words}')\n",
        "print(f\"5 least common words: {bottom_5_words}\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 10000\n",
            "5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NTOqbCAE0bw"
      },
      "source": [
        "[UNK] - unknown token - stands for unknown (word out of the vocabulary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvYKbXC5Eo5Z"
      },
      "source": [
        "### Creating an Embedding using an Embedding Layer\n",
        "\n",
        "To make our embedding, we're going to use Tensorflow's embedding layer.\n",
        "\n",
        "The parameters we care most about for our embedding layer:    \n",
        "* `input_dim` = the size of our vocabulary\n",
        "* ` output_dim` = the size of the output embedding vector, for example, a value of 100 would mean each token gets represented by a vector 100 long\n",
        "* `input_length` = length of the sequences being passed to the embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpPbkWIhH0uD",
        "outputId": "a6bff5bc-ea19-4a90-b079-07a23b8f9adf"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
        "                             output_dim=128,\n",
        "                             input_length=max_length)\n",
        "\n",
        "embedding"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.embeddings.Embedding at 0x7f5dd97180d0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_ZGMsB7JpZc",
        "outputId": "65325680-0bac-43d0-9ca2-e532e190d98b"
      },
      "source": [
        "# Get a random sentence from the training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n {random_sentence}\\\n",
        "        \\n\\nEmbedded version:\")\n",
        "\n",
        "# embed the random sentence (turn positive indexes into dense vectors of fixed size)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            " sevenfigz has a crush: http://t.co/20B3PnQxMD        \n",
            "\n",
            "Embedded version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[-0.0203002 ,  0.00215209, -0.02582103, ...,  0.00859997,\n",
              "         -0.04831581,  0.04421609],\n",
              "        [-0.01357088,  0.02903391,  0.00575   , ...,  0.04502719,\n",
              "         -0.02778864,  0.03256688],\n",
              "        [ 0.03108105, -0.01318034, -0.04170885, ...,  0.04538057,\n",
              "          0.01782098,  0.04630543],\n",
              "        ...,\n",
              "        [ 0.02933514, -0.03474209,  0.03329865, ..., -0.04839624,\n",
              "          0.01408224,  0.00835831],\n",
              "        [ 0.02933514, -0.03474209,  0.03329865, ..., -0.04839624,\n",
              "          0.01408224,  0.00835831],\n",
              "        [ 0.02933514, -0.03474209,  0.03329865, ..., -0.04839624,\n",
              "          0.01408224,  0.00835831]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5kXKSQEKdXy",
        "outputId": "e17cacd0-7d8d-4cfe-b519-9da5abc52d20"
      },
      "source": [
        "# check out a single token's embedding\n",
        "sample_embed[0][0], sample_embed[0][0].shape, random_sentence.split()[0]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([-0.0203002 ,  0.00215209, -0.02582103,  0.02734051, -0.00222858,\n",
              "        -0.01783652, -0.0278393 , -0.01615239,  0.01724836,  0.00502839,\n",
              "        -0.02277929,  0.02568221,  0.01065608,  0.01973409,  0.03074135,\n",
              "        -0.00159981, -0.0031922 ,  0.01818543,  0.00411876,  0.02168863,\n",
              "        -0.04675899,  0.0236094 , -0.02252394, -0.04814444,  0.03934768,\n",
              "         0.00926523,  0.0278165 , -0.04606193,  0.00956136,  0.00306127,\n",
              "        -0.04133532, -0.03774905, -0.00203345,  0.00517522,  0.00903773,\n",
              "         0.01418817,  0.01408682, -0.04266986, -0.03235618,  0.04350537,\n",
              "         0.0324458 , -0.03937459, -0.0342259 , -0.04473131,  0.01437816,\n",
              "         0.01649487, -0.03793164, -0.03731943, -0.0307304 ,  0.00909276,\n",
              "        -0.03189919,  0.0398565 , -0.03192563,  0.02756849,  0.02549621,\n",
              "         0.02560022,  0.0373757 ,  0.00596725,  0.04676963, -0.04904911,\n",
              "        -0.01454911,  0.00238641, -0.00550079, -0.04478306,  0.02580705,\n",
              "         0.04185355, -0.02026243, -0.03885038,  0.0327371 , -0.02328347,\n",
              "        -0.03371849,  0.00130857, -0.03944683, -0.01845026,  0.01441482,\n",
              "        -0.02618636,  0.04416886, -0.04986913, -0.00488915, -0.01867725,\n",
              "        -0.04917022, -0.03525574,  0.0475612 ,  0.03990958,  0.04160162,\n",
              "         0.0439721 , -0.02133166,  0.01040838, -0.00873522,  0.01251021,\n",
              "        -0.00865496,  0.01799246,  0.02816615,  0.00729639, -0.00328752,\n",
              "         0.01173679, -0.01304422, -0.0298677 ,  0.03105268,  0.00493092,\n",
              "         0.02242669, -0.00099536, -0.024694  ,  0.02153147, -0.03719947,\n",
              "         0.0267137 , -0.04949785,  0.0146641 ,  0.03416279,  0.02023068,\n",
              "         0.03550831,  0.0046482 ,  0.04393156,  0.04900307,  0.00446049,\n",
              "         0.01276573, -0.00406158,  0.03865776,  0.02959093,  0.02382589,\n",
              "        -0.00092976,  0.00910576,  0.0187231 ,  0.04460413,  0.02647883,\n",
              "         0.00859997, -0.04831581,  0.04421609], dtype=float32)>,\n",
              " TensorShape([128]),\n",
              " 'sevenfigz')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFYIT7bYLG68"
      },
      "source": [
        "## Modelling a text dataset\n",
        "\n",
        "Now we've got a way to turn our tetxt sequences into numbers, it's time to start building a series of modelling experiments.\n",
        "\n",
        "Let;s start with a baseline and move on from there.\n",
        "\n",
        " * Model 0: Naive Bayes (baseline) \n",
        " * Model 1: Feed-forward neural network\n",
        " * Model 2: LSTM model (RNN)\n",
        " * Model 3: GRU model (RNN)\n",
        " * Model 4: Bidirectional-LSTM model (RNN)\n",
        " * Model 5: 1D Convolutional Neural network (CNN)\n",
        " * Model 6: Tensorflow Hub pretrained feature extractor (using transfer learning for NLP)\n",
        " * Model 7: Same as model 6 with 10% of training data\n",
        "\n",
        "We will use the standard steps in modelling with tensorflow:    \n",
        "* Create a model\n",
        "* Build a model\n",
        "* Fit the model\n",
        "* Evaluate the model\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT7fx98DMjNE"
      },
      "source": [
        "### Model 0: Getting a Baseline Model\n",
        "\n",
        "As with all machine elarning modelling experiments, it's important to create a baseline model so you've gto a benchmark for future experiments to build upon.\n",
        "\n",
        "To create our baseline, we'll sue Sklearn's Multinomial Naive Bayes using the TF-IDF formula to convert our words to numbers.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5G5fcyWjdG88",
        "outputId": "d5b46fd4-7436-4ac8-99d6-469b40fc72d9"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
        "                    (\"clf\", MultinomialNB()) # model the text\n",
        "])\n",
        "\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqf5Rop-eARm",
        "outputId": "c15ed26f-5eee-4502-83ff-171452d27fb8"
      },
      "source": [
        "# evaluate our baseline model\n",
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"Our baseline model achieves an accuracy of :{baseline_score*100:.2f}%\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our baseline model achieves an accuracy of :79.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ro964ZZfefBA",
        "outputId": "6183220b-fe59-44e2-dbc7-bc2820280822"
      },
      "source": [
        "train_df.target.value_counts() # slightly imbalanced classes"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3bgCs5CepS1",
        "outputId": "1dfc4b8e-09a0-4119-a81e-106ee53989bb"
      },
      "source": [
        "# make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:10]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1qeRO9Ce1TB"
      },
      "source": [
        "### Creating an evaluation function for our model experiments\n",
        "\n",
        "Let's create a function to compare our model's predictions with the truth label using the following metrics:   \n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJdgW8Qmf0uS"
      },
      "source": [
        "# Function to evaluate: accuracy , precision, recall , f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  '''\n",
        "  Calculates model accuracy, precision, recall and f1-score of a binary classification model.\n",
        "  '''\n",
        "  # calculat model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred)*100\n",
        "  # calculate model precision, recall and f1-score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                   \"precision\": model_precision,\n",
        "                   \"recall\": model_recall,\n",
        "                   \"f1\": model_f1}\n",
        "  return model_results "
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uM_EP9FyBLkY",
        "outputId": "b918c253-7ba9-4af4-c10c-46d693dcb10c"
      },
      "source": [
        "# get baseline results\n",
        "baseline_results = calculate_results(y_true = val_labels,\n",
        "                                     y_pred = baseline_preds)\n",
        "baseline_results"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6q-_UsUPBZRl"
      },
      "source": [
        "### Model 1: A simple dense model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gvc5YrMFJpJ"
      },
      "source": [
        "# Create a tensorboard callback (need to create a new one for each model)\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create a directory to save tensorboard logs\n",
        "SAVE_DIR = \"model_logs\"\n",
        "\n",
        "# Build the model with functional API\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string) # inputs are 1-dimensional strings\n",
        "x = text_vectorizer(inputs) # turn the input text into numbers\n",
        "x = embedding(x)  # create an embedding of numberized inputs\n",
        "x = layers.GlobalAveragePooling1D()(x)  # condense the feature vector for each token to one vector\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)  # create the output layer, want binary outputs so use sigmoid activation function\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\")"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICsa8Ei9Gh3d",
        "outputId": "84459747-a860-442f-fea9-6bc9732b0295"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGvM1kuOJktO",
        "outputId": "260780e9-84f2-4f3a-d227-c1916796b506"
      },
      "source": [
        "# Compile the model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# fit the model\n",
        "model_1_history = model_1.fit(x=train_sentences,\n",
        "                              y=train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                     experiment_name=\"model_1_dense\")])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_1_dense/20211122-104119\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 4s 15ms/step - loss: 0.6153 - accuracy: 0.6828 - val_loss: 0.5382 - val_accuracy: 0.7520\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.4427 - accuracy: 0.8140 - val_loss: 0.4702 - val_accuracy: 0.7848\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.3473 - accuracy: 0.8581 - val_loss: 0.4618 - val_accuracy: 0.7900\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.2850 - accuracy: 0.8907 - val_loss: 0.4609 - val_accuracy: 0.7874\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.2377 - accuracy: 0.9123 - val_loss: 0.4792 - val_accuracy: 0.7795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FVMHTOXK8ya",
        "outputId": "e3f64c3f-8094-4be5-8313-504db4452aa0"
      },
      "source": [
        "# check the results\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7795\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4791695177555084, 0.7795275449752808]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lz1K4lVWNq6q",
        "outputId": "ea6cc788-ce58-4d3c-835c-c767791257e2"
      },
      "source": [
        "#make some predictions and evaluate those\n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(762, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__TAaqlDOG9Z",
        "outputId": "3a2efd0e-5b2d-41ac-eedd-b476d1ee208d"
      },
      "source": [
        "# look at a single prediction\n",
        "model_1_pred_probs[0]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.45622128], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhSWFqqAOKv_",
        "outputId": "9ff66b02-2eb5-4d24-ade5-af514ae9b2f2"
      },
      "source": [
        "# Look  at the first 10 predictions\n",
        "model_1_pred_probs[:10]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.45622128],\n",
              "       [0.8286478 ],\n",
              "       [0.9973845 ],\n",
              "       [0.17302817],\n",
              "       [0.1397669 ],\n",
              "       [0.9487127 ],\n",
              "       [0.92397976],\n",
              "       [0.9933723 ],\n",
              "       [0.97342217],\n",
              "       [0.37792838]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXHYCisy_Ocy",
        "outputId": "16d48bd1-4541-4a9a-c4e8-a3ea16553a90"
      },
      "source": [
        "# convert model prediction probabilities to label format\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
        "model_1_preds[:10]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GP7ehTMf_tqN",
        "outputId": "4edf2f05-fa56-4f05-f16b-c6a8329dfb73"
      },
      "source": [
        "# calculate model_1 results\n",
        "model_1_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.95275590551181,\n",
              " 'f1': 0.7782139444386276,\n",
              " 'precision': 0.7800661437025787,\n",
              " 'recall': 0.7795275590551181}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bSwjYt_AFap",
        "outputId": "790a12dd-e599-4467-f230-4c1ea95127f3"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dMvXvPxAG2h",
        "outputId": "eb2cddd9-b349-4d0e-be42-6f97425b959f"
      },
      "source": [
        "import numpy as np\n",
        "np.array(list(model_1_results.values())) >  np.array(list(baseline_results.values()))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C47EvWAKBQYf"
      },
      "source": [
        "Comparing results shows that baseline model outperforms our first deep leanring based dense model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slk7X5DgA03F"
      },
      "source": [
        "## Visualizing learned embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CocykaRtB2FE"
      },
      "source": [
        "# Get the vocabulary from the text vectorization layer\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_412_vTCO_5",
        "outputId": "bf27ca33-2716-49cd-b1ed-fef14c45aa34"
      },
      "source": [
        "len(words_in_vocab)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QthdATdYCQCc",
        "outputId": "4a23cd3f-66b8-49dc-89b3-4d68678d2ea0"
      },
      "source": [
        "# first 10 most common words\n",
        "words_in_vocab[:10]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is']"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xr565Nt4CYhp",
        "outputId": "74eb6c79-3c27-4c99-dbc5-dfd763727a2c"
      },
      "source": [
        "max_vocab_length"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6NlW5BLCiNS",
        "outputId": "7fb98496-b8b1-4dd9-93e1-edc47f16b619"
      },
      "source": [
        "# Model 1 summary\n",
        "model_1.summary()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2h1X9btACuxY",
        "outputId": "c956dabf-cd04-426a-ed6f-6e5762a6deb4"
      },
      "source": [
        "# get the weight matrix of embedding layer\n",
        "# (these are the numerical representations of each token in our training data which have been learned for 5 epochs)\n",
        "embed_weights = model_1.get_layer(\"embedding\").get_weights()[0]\n",
        "embed_weights"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3.8385056e-02, -4.7353119e-02,  4.6584837e-02, ...,\n",
              "        -6.0158819e-02,  4.6870811e-03,  2.1711888e-02],\n",
              "       [ 2.8403914e-02, -2.2560526e-02, -1.4389919e-02, ...,\n",
              "        -3.4286316e-02,  9.7355284e-03,  2.0338704e-03],\n",
              "       [ 1.3427482e-02,  3.4878958e-05,  1.3292749e-02, ...,\n",
              "         2.7343327e-02, -5.6827657e-02, -1.7926883e-02],\n",
              "       ...,\n",
              "       [ 1.1249363e-02, -1.6342677e-02,  5.8816783e-03, ...,\n",
              "         3.4679297e-02, -2.2218466e-02,  4.7546808e-02],\n",
              "       [-5.8688197e-02, -2.1273028e-02,  8.0851689e-02, ...,\n",
              "        -5.0424073e-02, -4.5028284e-02,  5.1087281e-03],\n",
              "       [-8.3761051e-02, -7.6656334e-02,  7.7271469e-02, ...,\n",
              "        -8.6627916e-02, -8.5301615e-02,  6.7009456e-03]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sp63iproFU2o",
        "outputId": "475aaadc-bad4-4b37-ab1c-8ad2bdd86d5d"
      },
      "source": [
        "print(embed_weights.shape) # same size as vocab size and embedding_dim (output_dim of embedding layer)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRSwuPlcGSff"
      },
      "source": [
        "Now we've got the embedding matrix our model has learned to represent our tokens, let's see how we can visualize it:    \n",
        "\n",
        "To do so, Tensorflow has a handy tool called **Projector**: http://projector.tensorflow.org/\n",
        "\n",
        "And TensorFlow also has an incredible guide on **word embeddings** themselves: https://www.tensorflow.org/text/guide/word_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOckRkE7FX1b"
      },
      "source": [
        "# # create embedding files (we've got this from Tensorflow's word embeddings documentation)\n",
        "# import io\n",
        "# out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "# out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "# for index, word in enumerate(words_in_vocab):\n",
        "#   if index == 0:\n",
        "#     continue  # skip 0, it's padding.\n",
        "#   vec = embed_weights[index]\n",
        "#   out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "#   out_m.write(word + \"\\n\")\n",
        "# out_v.close()\n",
        "# out_m.close()"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cm0RPo7LdY4N"
      },
      "source": [
        "# # Download files from colab to upload to projector\n",
        "# try:\n",
        "#   from google.colab import files\n",
        "#   files.download('vectors.tsv')\n",
        "#   files.download('metadata.tsv')\n",
        "# except Exception:\n",
        "#   pass"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "symtnafJh3qs"
      },
      "source": [
        "## Recurrent Neural Networks (RNN's)\n",
        "\n",
        "RNNs are useful for sequence data.\n",
        "\n",
        "The premise of a recurrent neural network is to use the representation of a previous input to aid the representation of a later input.\n",
        "\n",
        "- MIT deep learning: http://introtodeeplearning.com/\n",
        "- Andrej Karpathy's blog post: http://karpathy.github.io/2015/05/21/rnn-effectiveness/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReAiU9Rregxr"
      },
      "source": [
        "### Model 2 - LSTM\n",
        "\n",
        "LSTM stands for **Long short term memory** (one of the most popular LSTM cells)\n",
        "\n",
        "Our structure of an RNN typically looks like this:    \n",
        "```\n",
        "Input (text) -> Tokenize -> Embedding -> Layers (RNN/Dense) -> Output (label probability)\n",
        "``` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2X5MgU1LmA6N",
        "outputId": "1eb70456-751d-4e28-b96a-6b02334d41cb"
      },
      "source": [
        "# Create an LSTM model\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "print(x.shape)\n",
        "x = layers.LSTM(64, return_sequences=True)(x) # when you're stacking RNN cells together, you need to return_sequences = true  \n",
        "print(x.shape)\n",
        "x = layers.LSTM(64)(x)\n",
        "# print(x.shape)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x)\n",
        "# print(x.shape)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\") "
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 15, 128)\n",
            "(None, 15, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzOgNQIKnyxj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f811285-2525-4008-e294-65880af54b6c"
      },
      "source": [
        "# Get a summary\n",
        "model_2.summary()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 15, 64)            49408     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                33024     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,362,497\n",
            "Trainable params: 1,362,497\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OKpTE3PPvud"
      },
      "source": [
        "# compile the model\n",
        "model_2.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzQ65HcsQEvV",
        "outputId": "0f8e13c9-1885-44f6-bb88-8bd0b91893e9"
      },
      "source": [
        "# fit the model\n",
        "model_2_history = model_2.fit(x=train_sentences,\n",
        "                              y=train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,experiment_name=\"model_2_LSTM\")])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_LSTM/20211122-104136\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 13s 42ms/step - loss: 0.2211 - accuracy: 0.9196 - val_loss: 0.5777 - val_accuracy: 0.7835\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.1595 - accuracy: 0.9423 - val_loss: 0.6118 - val_accuracy: 0.7756\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.1305 - accuracy: 0.9508 - val_loss: 0.7558 - val_accuracy: 0.7822\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.1025 - accuracy: 0.9603 - val_loss: 0.7339 - val_accuracy: 0.7717\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0806 - accuracy: 0.9666 - val_loss: 0.9060 - val_accuracy: 0.7730\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JtO5SHfQj7L",
        "outputId": "e6083826-d391-4782-b7cd-2e2ca01c0e51"
      },
      "source": [
        "# Make predictions with LSTM model\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs[:10]"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.2859763e-02],\n",
              "       [7.4106771e-01],\n",
              "       [9.9958718e-01],\n",
              "       [2.4042755e-02],\n",
              "       [1.8534064e-04],\n",
              "       [9.9704087e-01],\n",
              "       [9.6567035e-01],\n",
              "       [9.9970818e-01],\n",
              "       [9.9940169e-01],\n",
              "       [5.7925928e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Im2oiiJsQ6Ij",
        "outputId": "d341e69a-e608-4951-cdd9-054ca99707ef"
      },
      "source": [
        "# Convert model 2 pred probs to labels\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_P9vY4xRK9R"
      },
      "source": [
        "# Calculate model 2 results\n",
        "model_2_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_2_preds)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpTE5aq5RXjd",
        "outputId": "000daf3b-5ee4-4d1b-a4a0-b0cb7ea3ee3e"
      },
      "source": [
        "model_2_results"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.29658792650919,\n",
              " 'f1': 0.7718716556605149,\n",
              " 'precision': 0.7730528656214299,\n",
              " 'recall': 0.7729658792650919}"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMBHLvq5RZSZ",
        "outputId": "d847caa3-f7c4-4e35-b252-9cb3ebf2ca0e"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yxLVPdkRb2-"
      },
      "source": [
        "### Model 3: GRU\n",
        "\n",
        "Another popular and effective RNN component is the **GRU** or **gated recurrent unit**.\n",
        "\n",
        "The GRU cell has similar features to an LSTM cell but has less parameters.\n",
        "\n",
        "Resource: https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUhuV6FvSK_n"
      },
      "source": [
        "# Build an RNN using the GRU cell\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# x = layers.GRU(64, return_sequences=True)(x) # if you want to stack RNN layers on top of each other, you need return_sequences=True\n",
        "# x = layers.LSTM(64, return_sequences=True)(x)\n",
        "x = layers.GRU(64)(x)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlj7JHovVM_9",
        "outputId": "04a86f42-222f-4836-c1a4-1748ee416631"
      },
      "source": [
        "# get a summary\n",
        "model_3.summary()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 64)                37248     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYsTB6WKVpvx"
      },
      "source": [
        "# compile the model\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqKQJlAUWuaF",
        "outputId": "bf257674-9765-4209-d55d-5b93ae6ad128"
      },
      "source": [
        "# fit the model\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"model_3_GRU\")])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_3_GRU/20211122-104303\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 9s 29ms/step - loss: 0.1606 - accuracy: 0.9393 - val_loss: 0.8278 - val_accuracy: 0.7795\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 6s 26ms/step - loss: 0.0853 - accuracy: 0.9682 - val_loss: 0.9512 - val_accuracy: 0.7822\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 6s 27ms/step - loss: 0.0643 - accuracy: 0.9721 - val_loss: 1.2882 - val_accuracy: 0.7769\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 6s 26ms/step - loss: 0.0550 - accuracy: 0.9765 - val_loss: 1.1244 - val_accuracy: 0.7795\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 6s 26ms/step - loss: 0.0508 - accuracy: 0.9749 - val_loss: 1.0973 - val_accuracy: 0.7769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41hTTx6bXGgy",
        "outputId": "d3f438c7-57e3-498e-d18a-4cd3f2a32fd7"
      },
      "source": [
        "# make some predictions with our gru model\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs[:10]"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.0292709e-02],\n",
              "       [7.2140318e-01],\n",
              "       [9.9989104e-01],\n",
              "       [1.4145780e-01],\n",
              "       [1.1082457e-04],\n",
              "       [9.9981654e-01],\n",
              "       [9.9337071e-01],\n",
              "       [9.9994862e-01],\n",
              "       [9.9992692e-01],\n",
              "       [6.2805980e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1Ct7sd3XSKK",
        "outputId": "14042a89-fe71-4503-94e5-0e5de0e24d86"
      },
      "source": [
        "# convert model 3 pred probs to labels\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiJuyUWVXgCw",
        "outputId": "39acf33e-41b6-492b-a11e-7088ba1f22d3"
      },
      "source": [
        "# calculate model 3 results\n",
        "model_3_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_3_preds)\n",
        "model_3_results"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.69028871391076,\n",
              " 'f1': 0.7755736342533732,\n",
              " 'precision': 0.7773989686400665,\n",
              " 'recall': 0.7769028871391076}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlwVOyG-XsQ-",
        "outputId": "1c4bb80c-d3a0-4a3b-da1f-7e3d54702504"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaQSTxN5XuIX"
      },
      "source": [
        "### Model 4: Bidirectional RNN\n",
        "\n",
        "Normal RNN's go from left to right however, bidirectional RNN goes from right to left as well as left to right."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vt_o-WAfY7WJ"
      },
      "source": [
        "# build a bidirectional RNN\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_bidirectional\")"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzTHUwErZ17d",
        "outputId": "79b4e1d6-6209-4ede-c6c3-9e3f1c769eb3"
      },
      "source": [
        "# Get a summary\n",
        "model_4.summary()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_bidirectional\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              98816     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiwRv-bnZ7Ag"
      },
      "source": [
        "# compile the model\n",
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmWxNAsibXdN",
        "outputId": "bc39fc7e-6b3a-4df0-acf0-bda7812ed3eb"
      },
      "source": [
        "# fit the model\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\"model_4_bidirectional\")])"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_4_bidirectional/20211122-104336\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 13s 42ms/step - loss: 0.1077 - accuracy: 0.9689 - val_loss: 0.8661 - val_accuracy: 0.7769\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0544 - accuracy: 0.9768 - val_loss: 1.0917 - val_accuracy: 0.7572\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0450 - accuracy: 0.9783 - val_loss: 1.1119 - val_accuracy: 0.7677\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0420 - accuracy: 0.9797 - val_loss: 1.4523 - val_accuracy: 0.7651\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0404 - accuracy: 0.9801 - val_loss: 1.4016 - val_accuracy: 0.7690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhbwT_Jkb0WR",
        "outputId": "15230c55-c87c-4f9b-ca15-7858c3850adc"
      },
      "source": [
        "# make predictions with bidirectional model\n",
        "model_4_pred_probs = model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.2894245e-01],\n",
              "       [8.0197388e-01],\n",
              "       [9.9998462e-01],\n",
              "       [3.0803937e-01],\n",
              "       [1.1418936e-05],\n",
              "       [9.9996138e-01],\n",
              "       [9.8812330e-01],\n",
              "       [9.9999452e-01],\n",
              "       [9.9998510e-01],\n",
              "       [8.0553651e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EEzpAsocCdt",
        "outputId": "173ffd62-0e12-4066-dea8-ade87af39bc4"
      },
      "source": [
        "# convert pred probs to labels\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DK8dkDDcJri",
        "outputId": "1e7a7b8f-a575-4070-9724-ab4b6517ef95"
      },
      "source": [
        "# calculate the results of bidirectional model\n",
        "model_4_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_4_preds)\n",
        "model_4_results"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.9028871391076,\n",
              " 'f1': 0.7678647757387915,\n",
              " 'precision': 0.7691242349168363,\n",
              " 'recall': 0.7690288713910761}"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyjLsS13cZsy"
      },
      "source": [
        "## Convolutional Neural Networks for Text ( and other types of sequences)\n",
        "\n",
        "CNNs are typically used for images but images are 2D (height*width)..however text data is 1D.\n",
        "\n",
        "Conv2D is used for image data but Conv1D can be used for text.\n",
        "\n",
        "The typical structure of a Conv1D model fr sequences:    \n",
        "\n",
        "```\n",
        "Input (text) -> Tokenization -> Embedding -> Layer(s) (typically Conv1D + Pooling) -> Ouputs (class probabilities)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkThbjASdYe7"
      },
      "source": [
        "### Model 5: Conv1D\n",
        "\n",
        "For different explanations of parameters, see:    \n",
        "* https://poloclub.github.io/cnn-explainer/\n",
        "* Difference between same and valid padding: stackoverflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vElAN7tOeWT-",
        "outputId": "cfbd0b8c-a44a-4a6f-a1ce-a03d07a21994"
      },
      "source": [
        "# Test out our embedding layer, Conv1D layer and max pooling\n",
        "from tensorflow.keras import layers\n",
        "embedding_test = embedding(text_vectorizer([\"this is a test sentence\"])) # turn target sequence into embedding\n",
        "conv_1d = layers.Conv1D(filters=64,\n",
        "                        kernel_size=5, # this is also refereed to as  ngram of 5 (it looks at 5 words at a time)\n",
        "                        activation=\"relu\",\n",
        "                        padding=\"valid\") #(output is smaller than the input shape with \"valid\")\n",
        "conv_1d_output = conv_1d(embedding_test) # pass test embedding through conv1d layer\n",
        "max_pool = layers.GlobalMaxPool1D()\n",
        "max_pool_output = max_pool(conv_1d_output)  # equivalent to 'get the most important feature' or 'get the feature with the highest value'\n",
        "\n",
        "\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 11, 64]), TensorShape([1, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWe-2vS5gFLw"
      },
      "source": [
        "# embedding_test"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mX1fFWhiY7H"
      },
      "source": [
        "# conv_1d_output"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFf4XXgCicJo"
      },
      "source": [
        "# max_pool_output"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEc3J9ERiq3N",
        "outputId": "7b1c7d06-96c6-45f4-8a99-bf4715b5b083"
      },
      "source": [
        "# Create 1-dimensional convolutional layer to model sequences\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Conv1D(filters=64,\n",
        "                  kernel_size=5,\n",
        "                  activation=\"relu\",\n",
        "                  strides=1,\n",
        "                  padding=\"valid\")(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")\n",
        "\n",
        "# Compile the model\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# get summary of model\n",
        "model_5.summary()\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5_Conv1D\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 11, 64)            41024     \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 64)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,321,089\n",
            "Trainable params: 1,321,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b2i_Nuc57P_",
        "outputId": "a831caab-73b5-476b-ba5a-587264fa58bf"
      },
      "source": [
        "# fit the model\n",
        "model_5_history = model_5.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\"model_5_Conv1D\")])"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_5_Conv1D/20211122-104423\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 19ms/step - loss: 0.1279 - accuracy: 0.9585 - val_loss: 0.8726 - val_accuracy: 0.7730\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0775 - accuracy: 0.9707 - val_loss: 1.0438 - val_accuracy: 0.7677\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0616 - accuracy: 0.9769 - val_loss: 1.1765 - val_accuracy: 0.7677\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0554 - accuracy: 0.9787 - val_loss: 1.2231 - val_accuracy: 0.7638\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0519 - accuracy: 0.9787 - val_loss: 1.2235 - val_accuracy: 0.7625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "224G7T_k63Az",
        "outputId": "bccd8c08-458c-461f-f230-4be6061f50dc"
      },
      "source": [
        "# make predictions\n",
        "model_5_pred_probs = model_5.predict(val_sentences)\n",
        "model_5_pred_probs[:10]"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.2934722e-01],\n",
              "       [5.7011151e-01],\n",
              "       [9.9994779e-01],\n",
              "       [6.7446828e-02],\n",
              "       [1.8069576e-07],\n",
              "       [9.9924183e-01],\n",
              "       [9.5093536e-01],\n",
              "       [9.9992442e-01],\n",
              "       [9.9999809e-01],\n",
              "       [9.6639478e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRO-0ILw7AKq",
        "outputId": "e8e7ab2c-5717-4ec2-a453-51eb8309190a"
      },
      "source": [
        "# turn probailities into labels\n",
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_preds[:10]"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmWJTlqI7Kgu",
        "outputId": "3da6aad5-b5e6-4688-da0a-6f14170c5ac5"
      },
      "source": [
        "# Evaluate model_5 predictions\n",
        "model_5_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_5_preds)\n",
        "model_5_results"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.24671916010499,\n",
              " 'f1': 0.7614244466786471,\n",
              " 'precision': 0.762323768273959,\n",
              " 'recall': 0.7624671916010499}"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqEt0JAk7VOw"
      },
      "source": [
        "## Model 6: Tensorflow Hub Pretrained Sentence Encoder\n",
        "\n",
        "Let's try and use transfer learning for NLP, specifically using Tensorflow Hub's **Universal Sentence Encoder (USE)**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq_IAf3D_uiT"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "embed_samples = embed([sample_sentence,\n",
        "                       \"When you call the universal sentence encoder on a sentence, it turns it into numbers\"])"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQK6bTBSCabH",
        "outputId": "81967e54-d8b0-4c1e-e252-ac3c963f3ab1"
      },
      "source": [
        "print(embed_samples[0][:50])"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[-0.01157025  0.02485911  0.02878051 -0.012715    0.03971541  0.08827761\n",
            "  0.02680988  0.05589839 -0.01068731 -0.00597293  0.00639321 -0.01819516\n",
            "  0.00030816  0.09105889  0.05874646 -0.03180629  0.01512474 -0.05162925\n",
            "  0.00991366 -0.06865345 -0.04209306  0.0267898   0.03011009  0.00321065\n",
            " -0.00337968 -0.04787357  0.0226672  -0.00985927 -0.04063615 -0.01292093\n",
            " -0.04666382  0.05630299 -0.03949255  0.00517682  0.02495827 -0.07014439\n",
            "  0.0287151   0.0494768  -0.00633978 -0.08960193  0.02807119 -0.00808364\n",
            " -0.01360601  0.05998649 -0.10361788 -0.05195373  0.00232958 -0.02332531\n",
            " -0.03758106  0.03327729], shape=(50,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VR2Y8Cg9CvoH",
        "outputId": "8482e396-4605-4e3f-b935-d85b3c36246d"
      },
      "source": [
        "embed_samples.shape # there are 2 example sentences"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dM5rAcBACzHu",
        "outputId": "1e6eb0df-304d-4919-96eb-7478c1b252f2"
      },
      "source": [
        "embed_samples[0].shape"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([512])"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCia4LSiDKGf"
      },
      "source": [
        "Transforms one whole sequence into a feature vector of length 512 (512 dimensional vector)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2KJQshhDI_9"
      },
      "source": [
        "# Create a keras layer using the USE pretrained layer from tensorflow hub\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[],\n",
        "                                        dtype=tf.string,\n",
        "                                        trainable=False,\n",
        "                                        name=\"USE\")"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-ZzP_7mEliI",
        "outputId": "92d80bf3-f876-4a24-944a-5a47e1a71cb0"
      },
      "source": [
        "# Create model using the sequential API\n",
        "model_6 = tf.keras.Sequential([\n",
        "    sentence_encoder_layer,\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\")\n",
        "], name=\"model_6_USE\")\n",
        "\n",
        "# Compile the model\n",
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# get the summary\n",
        "model_6.summary()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnRyoEy8FQiS",
        "outputId": "ad425891-346f-40d2-d9a5-dbf738a7ee78"
      },
      "source": [
        "# train a classifier on top of USE pretrained embeddings\n",
        "model_6_history = model_6.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\"model_6_tf_hub_USE\")])"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_6_tf_hub_USE/20211122-104507\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 6s 14ms/step - loss: 0.5003 - accuracy: 0.7911 - val_loss: 0.4480 - val_accuracy: 0.7979\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.4140 - accuracy: 0.8155 - val_loss: 0.4388 - val_accuracy: 0.8071\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.4007 - accuracy: 0.8212 - val_loss: 0.4378 - val_accuracy: 0.8045\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.3925 - accuracy: 0.8270 - val_loss: 0.4314 - val_accuracy: 0.8123\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.3859 - accuracy: 0.8288 - val_loss: 0.4244 - val_accuracy: 0.8123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIOWl_zZFqmb",
        "outputId": "6fa34795-74d0-4643-e759-7a97974162f7"
      },
      "source": [
        "# make predictions\n",
        "model_6_pred_probs = model_6.predict(val_sentences)\n",
        "model_6_pred_probs[:10]"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.19070137],\n",
              "       [0.8026762 ],\n",
              "       [0.9873236 ],\n",
              "       [0.26826313],\n",
              "       [0.7479439 ],\n",
              "       [0.70943165],\n",
              "       [0.98310673],\n",
              "       [0.9794288 ],\n",
              "       [0.9311701 ],\n",
              "       [0.08539233]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDMOU6yAF9lf",
        "outputId": "0c01c32c-6a4e-48e2-b40b-cbc5fdfcf553"
      },
      "source": [
        "# convert probailities to labels\n",
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds[:10]"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rg9To9ndGFNR",
        "outputId": "f87c1e2d-c522-4fad-e868-e8c2c1095399"
      },
      "source": [
        "# Evaluate model_6 predictions\n",
        "model_6_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_6_preds)\n",
        "model_6_results"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.23359580052494,\n",
              " 'f1': 0.8115121319063344,\n",
              " 'precision': 0.812763224356635,\n",
              " 'recall': 0.8123359580052494}"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdcGfRANGRLq",
        "outputId": "f1af4b2d-f716-4c65-ea31-c9668626fb6a"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhlAKBI6GTXh",
        "outputId": "75f93d65-a5b9-4008-c2db-88bf3c0a053d"
      },
      "source": [
        "# compare model_6 and baseline results\n",
        "np.array(list(model_6_results.values())) > np.array(list(baseline_results.values()))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jubSH-43IUF9"
      },
      "source": [
        "Finally tensorflow hub's pretrained USE feature extractor has outperformed our baseline model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ix0cyj1AGagT",
        "outputId": "ea5bf1f7-164f-4d1d-f38b-98341525e8a0"
      },
      "source": [
        "len(train_sentences)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6851"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ulh7i57LIgAh"
      },
      "source": [
        "## Model 7: TF Hub Pretrained USE but with 10% of training data\n",
        "\n",
        "Transfer learning really helps when you don't have a large dataset.\n",
        "\n",
        "To see how our model performs on a smaller dataser, let's replicate `model_6` except we'll train it on 10% data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xMB9JJrcJFpe",
        "outputId": "f39ed013-192d-4121-9c52-f1c6fde18f7d"
      },
      "source": [
        "# Create subsets of 10% of the training data\n",
        "train_df_shuffled.head()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "2644  3796  ...      1\n",
              "2227  3185  ...      0\n",
              "5448  7769  ...      1\n",
              "132    191  ...      0\n",
              "6845  9810  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk2HzEv6JPkK"
      },
      "source": [
        "# NOTE: making data splits like below leads to data leakage\n",
        "\n",
        "# create subsets of 10% of the training data\n",
        "# train_10_percent = train_df_shuffled[[\"text\", \"target\"]].sample(frac=0.1, random_state=42)\n",
        "# train_10_percent.head(), len(train_10_percent)"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKcySYL8J9jZ"
      },
      "source": [
        "# train_sentences_10_percent = train_10_percent[\"text\"].to_list()\n",
        "# train_labels_10_percent = train_10_percent[\"target\"].to_list()\n",
        "\n",
        "# len(train_sentences_10_percent), len(train_labels_10_percent)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NJhbvrIWagh",
        "outputId": "2be698ff-85bd-43ee-f73e-266185fda179"
      },
      "source": [
        "# Making a better dataset split (no data leakage)\n",
        "train_10_percent_split = int(0.1* len(train_sentences))\n",
        "train_10_percent_split"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "685"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlyuGrABWt6x"
      },
      "source": [
        "train_sentences_10_percent = train_sentences[:train_10_percent_split]\n",
        "train_labels_10_percent = train_labels[:train_10_percent_split]"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0nMBsRFXeT6",
        "outputId": "bb0a9202-4eed-44dd-9cb7-0e8c7cd86b36"
      },
      "source": [
        "pd.Series(train_labels_10_percent).value_counts()"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    406\n",
              "1    279\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxdrUk40YRWR",
        "outputId": "1c1d3e51-9970-4549-a12c-6ac6f3a0ead8"
      },
      "source": [
        "train_df_shuffled[\"target\"].value_counts()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HT04lto5Q-J8"
      },
      "source": [
        "To recreate a model same as a previous model you've created, you can use the `tf.keras.models.clone_model` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xl0L7dGdKnAX",
        "outputId": "5a6769ca-f590-4faf-defa-c295b1e0c876"
      },
      "source": [
        "# let's build a model same as model_6\n",
        "# model_7 = tf.keras.models.clone_model(model_6)\n",
        "model_7 = tf.keras.Sequential([\n",
        "    sentence_encoder_layer,\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\")                           \n",
        "], name=\"model_7_USE\")\n",
        "\n",
        "# compile model\n",
        "model_7.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# get a summary\n",
        "model_7.summary()"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0qccrd6Rr3m",
        "outputId": "d98f1947-b9e9-465e-cf73-8e6c9534270c"
      },
      "source": [
        "# fit the model to the 10% training data subsets\n",
        "model_7_history = model_7.fit(train_sentences_10_percent,\n",
        "                              train_labels_10_percent,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"model_7_tf_hub_correct_10_percent\")])"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_7_tf_hub_correct_10_percent/20211122-104531\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 3s 47ms/step - loss: 0.6695 - accuracy: 0.6759 - val_loss: 0.6505 - val_accuracy: 0.7100\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.5978 - accuracy: 0.8190 - val_loss: 0.5888 - val_accuracy: 0.7703\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.5214 - accuracy: 0.8190 - val_loss: 0.5366 - val_accuracy: 0.7782\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.4582 - accuracy: 0.8248 - val_loss: 0.5038 - val_accuracy: 0.7756\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.4174 - accuracy: 0.8394 - val_loss: 0.4910 - val_accuracy: 0.7795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pn5YM0mXSyVP",
        "outputId": "4138781d-d443-4aa5-def5-5b80703f7d4e"
      },
      "source": [
        "# make predictions with model_7\n",
        "model_7_pred_probs = model_7.predict(val_sentences)\n",
        "model_7_pred_probs[:10]"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.22934991],\n",
              "       [0.6328445 ],\n",
              "       [0.9082266 ],\n",
              "       [0.4035849 ],\n",
              "       [0.5909742 ],\n",
              "       [0.67726   ],\n",
              "       [0.87754095],\n",
              "       [0.80131805],\n",
              "       [0.83436394],\n",
              "       [0.1533468 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDTy_IMlS-Hl",
        "outputId": "45edaf3e-d089-468b-c4fd-afb119653f46"
      },
      "source": [
        "# covert probailities to labels\n",
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "model_7_preds[:10]"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Y1203yUTGO6",
        "outputId": "95801af9-c210-4dc7-8e1b-9f38362f3d06"
      },
      "source": [
        "# evaluate model_7 predictions\n",
        "model_7_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_7_preds)\n",
        "model_7_results"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.95275590551181,\n",
              " 'f1': 0.7782139444386276,\n",
              " 'precision': 0.7800661437025787,\n",
              " 'recall': 0.7795275590551181}"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8QiJzceTR8t",
        "outputId": "bc237819-2c2f-42ab-83bd-0e25a8537d41"
      },
      "source": [
        "model_6_results"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.23359580052494,\n",
              " 'f1': 0.8115121319063344,\n",
              " 'precision': 0.812763224356635,\n",
              " 'recall': 0.8123359580052494}"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9SIuvT9TaAm"
      },
      "source": [
        "We've only trained on 10% on data but our model is performing better than `model_6` trained on whole data!\n",
        "\n",
        "But how? Looks too good to be true.\n",
        "\n",
        "This is happening because of **data leakage** problem. Since both `validation set` and `train_10_percent` sets are created using `train_df_shuffled`, some of the validation data has leaked in train_10_percent set and model has already seen their labels.\n",
        "\n",
        "This should not be happening. Always be careful while making data splits.\n",
        "\n",
        "> **Do not make data splits which leak data from validation/test sets to training set**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h316EJzMTXwq"
      },
      "source": [
        "## Compare the performance of each of our models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "-eubw2D_bJmw",
        "outputId": "3ac4e277-fe4b-4336-b7db-eced1b11cdbf"
      },
      "source": [
        "# Combine model results into a dataframe\n",
        "all_model_results = pd.DataFrame({\"0_baseline\": baseline_results,\n",
        "                                  \"1_simple_dense\": model_1_results,\n",
        "                                  \"2_lstm\": model_2_results,\n",
        "                                  \"3_gru\": model_3_results,\n",
        "                                  \"4_bidirectional\": model_4_results,\n",
        "                                  \"5_conv1d\": model_5_results,\n",
        "                                  \"6_tf_hub_use_encoder\": model_6_results,\n",
        "                                  \"7_tf_hub_use_encoder_10_percent\": model_7_results})\n",
        "all_model_results = all_model_results.transpose()\n",
        "all_model_results"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_baseline</th>\n",
              "      <td>79.265092</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_simple_dense</th>\n",
              "      <td>77.952756</td>\n",
              "      <td>0.780066</td>\n",
              "      <td>0.779528</td>\n",
              "      <td>0.778214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_lstm</th>\n",
              "      <td>77.296588</td>\n",
              "      <td>0.773053</td>\n",
              "      <td>0.772966</td>\n",
              "      <td>0.771872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_gru</th>\n",
              "      <td>77.690289</td>\n",
              "      <td>0.777399</td>\n",
              "      <td>0.776903</td>\n",
              "      <td>0.775574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_bidirectional</th>\n",
              "      <td>76.902887</td>\n",
              "      <td>0.769124</td>\n",
              "      <td>0.769029</td>\n",
              "      <td>0.767865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_conv1d</th>\n",
              "      <td>76.246719</td>\n",
              "      <td>0.762324</td>\n",
              "      <td>0.762467</td>\n",
              "      <td>0.761424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6_tf_hub_use_encoder</th>\n",
              "      <td>81.233596</td>\n",
              "      <td>0.812763</td>\n",
              "      <td>0.812336</td>\n",
              "      <td>0.811512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7_tf_hub_use_encoder_10_percent</th>\n",
              "      <td>77.952756</td>\n",
              "      <td>0.780066</td>\n",
              "      <td>0.779528</td>\n",
              "      <td>0.778214</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  accuracy  precision    recall        f1\n",
              "0_baseline                       79.265092   0.811139  0.792651  0.786219\n",
              "1_simple_dense                   77.952756   0.780066  0.779528  0.778214\n",
              "2_lstm                           77.296588   0.773053  0.772966  0.771872\n",
              "3_gru                            77.690289   0.777399  0.776903  0.775574\n",
              "4_bidirectional                  76.902887   0.769124  0.769029  0.767865\n",
              "5_conv1d                         76.246719   0.762324  0.762467  0.761424\n",
              "6_tf_hub_use_encoder             81.233596   0.812763  0.812336  0.811512\n",
              "7_tf_hub_use_encoder_10_percent  77.952756   0.780066  0.779528  0.778214"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "y9KMwajJcLx3",
        "outputId": "b3f73471-8bb5-4e04-e23c-3a22d98d85ca"
      },
      "source": [
        "# Reduce the accuracy to the same scale as other metrics\n",
        "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100\n",
        "all_model_results"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_baseline</th>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_simple_dense</th>\n",
              "      <td>0.779528</td>\n",
              "      <td>0.780066</td>\n",
              "      <td>0.779528</td>\n",
              "      <td>0.778214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_lstm</th>\n",
              "      <td>0.772966</td>\n",
              "      <td>0.773053</td>\n",
              "      <td>0.772966</td>\n",
              "      <td>0.771872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_gru</th>\n",
              "      <td>0.776903</td>\n",
              "      <td>0.777399</td>\n",
              "      <td>0.776903</td>\n",
              "      <td>0.775574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_bidirectional</th>\n",
              "      <td>0.769029</td>\n",
              "      <td>0.769124</td>\n",
              "      <td>0.769029</td>\n",
              "      <td>0.767865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_conv1d</th>\n",
              "      <td>0.762467</td>\n",
              "      <td>0.762324</td>\n",
              "      <td>0.762467</td>\n",
              "      <td>0.761424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6_tf_hub_use_encoder</th>\n",
              "      <td>0.812336</td>\n",
              "      <td>0.812763</td>\n",
              "      <td>0.812336</td>\n",
              "      <td>0.811512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7_tf_hub_use_encoder_10_percent</th>\n",
              "      <td>0.779528</td>\n",
              "      <td>0.780066</td>\n",
              "      <td>0.779528</td>\n",
              "      <td>0.778214</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 accuracy  precision    recall        f1\n",
              "0_baseline                       0.792651   0.811139  0.792651  0.786219\n",
              "1_simple_dense                   0.779528   0.780066  0.779528  0.778214\n",
              "2_lstm                           0.772966   0.773053  0.772966  0.771872\n",
              "3_gru                            0.776903   0.777399  0.776903  0.775574\n",
              "4_bidirectional                  0.769029   0.769124  0.769029  0.767865\n",
              "5_conv1d                         0.762467   0.762324  0.762467  0.761424\n",
              "6_tf_hub_use_encoder             0.812336   0.812763  0.812336  0.811512\n",
              "7_tf_hub_use_encoder_10_percent  0.779528   0.780066  0.779528  0.778214"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "-3rhB2Hoc90Z",
        "outputId": "735eaf46-6a99-4622-c52c-30aa62fc66e4"
      },
      "source": [
        "# Plot and compare all of the model results\n",
        "all_model_results.plot(kind=\"bar\", figsize=(10,7)).legend(bbox_to_anchor=(1.0,1.0));"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "14Mi_cUOdWcr",
        "outputId": "1fbcfb3a-2746-4b9c-9691-31a48976078d"
      },
      "source": [
        "# Sort model results by f1-score\n",
        "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(8,6))"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5dcd0298d0>"
            ]
          },
          "metadata": {},
          "execution_count": 118
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fO_Dqs1peN-C"
      },
      "source": [
        "## Uploading our model training logs to TensorBoard.dev\n",
        "\n",
        "We can further inspect our model's performance using TensorBoard.dev: https://tensorboard.dev/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arxdp6wbfEgP",
        "outputId": "83f2d088-fbca-4fa5-c961-e713786dd9c7"
      },
      "source": [
        "# # View tensorboard logs of transfer learning modelling experiments (plus other models)\n",
        "# # Upload tensorboard dev records\n",
        "# !tensorboard dev upload --logdir ./model_logs/ \\\n",
        "#   --name \"NLP Modelling Experiments\" \\no\n",
        "#   --description \"Comparing multiple different types of model architecture on Kaggle's Tweets text classification dataset\" \\\n",
        "#   --one_shot # exit the uploader once uploading is finished"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-11-22 10:45:43.864096: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\n",
            "***** TensorBoard Uploader *****\n",
            "\n",
            "This will upload your TensorBoard logs to https://tensorboard.dev/ from\n",
            "the following directory:\n",
            "\n",
            "./model_logs/\n",
            "\n",
            "This TensorBoard will be visible to everyone. Do not upload sensitive\n",
            "data.\n",
            "\n",
            "Your use of this service is subject to Google's Terms of Service\n",
            "<https://policies.google.com/terms> and Privacy Policy\n",
            "<https://policies.google.com/privacy>, and TensorBoard.dev's Terms of Service\n",
            "<https://tensorboard.dev/policy/terms/>.\n",
            "\n",
            "This notice will not be shown again while you are logged into the uploader.\n",
            "To log out, run `tensorboard dev auth revoke`.\n",
            "\n",
            "Continue? (yes/NO) no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sE4dKP9iW2H"
      },
      "source": [
        "I've run my cell above, my modelling experiments are visible on Tensorboard.dev: https://tensorboard.dev/experiment/SooxYrGgR12U4SrqaIZekw/\n",
        "\n",
        "TensorBoard is great for quickly tracking experiments but for larger scale experiments and a whole bunch more tracking options, check out **weights & biases**: https://wandb.ai/site"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5z45DiKhhyQo"
      },
      "source": [
        "# gives list of tensorboard dev experiments we've run\n",
        "# !tensorboard dev list"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0igZpYPff9QE"
      },
      "source": [
        "# If you need to delete an experiment from Tensorboard, run the following:\n",
        "# !tensorboard dev delete --experiment_id SooxYrGgR12U4SrqaIZekw"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqTcYeZbjQB3"
      },
      "source": [
        "## Saving and loading a trained model\n",
        "\n",
        "There are two main formats to save a model in Tensorflow:    \n",
        "* HDF5 format\n",
        "* `SaveModel` format (default when using tensorflow)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "habJ41TrjfBt",
        "outputId": "923918b6-bb65-46a5-80ff-3045fc9ce439"
      },
      "source": [
        "model_6_results"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.23359580052494,\n",
              " 'f1': 0.8115121319063344,\n",
              " 'precision': 0.812763224356635,\n",
              " 'recall': 0.8123359580052494}"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuwZbNQCjxSU"
      },
      "source": [
        "# Save TF Hub sentence encoder model to HDF5 format\n",
        "model_6.save(\"model_6.h5\")"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUE9qwHHj8a2"
      },
      "source": [
        "# Load model with custom hub layer (required with HDF5 format)\n",
        "import tensorflow_hub as hub\n",
        "loaded_model_6 = tf.keras.models.load_model(\"model_6.h5\",\n",
        "                                            custom_objects={\"KerasLayer\": hub.KerasLayer})"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5o3LlFrckehq",
        "outputId": "c95edbe7-a49a-4018-dac9-8d4616fda402"
      },
      "source": [
        "# how does our loaded model perform?\n",
        "loaded_model_6.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 10ms/step - loss: 0.4244 - accuracy: 0.8123\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4244178831577301, 0.8123359680175781]"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRg62Kcyksky",
        "outputId": "cf4b224d-268c-47ac-e94e-fed7978c322e"
      },
      "source": [
        "model_6_results"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.23359580052494,\n",
              " 'f1': 0.8115121319063344,\n",
              " 'precision': 0.812763224356635,\n",
              " 'recall': 0.8123359580052494}"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8l8sRVIEQeYE"
      },
      "source": [
        "Now let's save to the `SavedModel` format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIa-YXc6kwOg",
        "outputId": "d3d51d30-bb52-442a-caca-9cec8d7921f2"
      },
      "source": [
        "# Save TF hub sentence encoder model to SavedModel format (default)\n",
        "model_6.save(\"model_6_SavedModel_format\")"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: model_6_SavedModel_format/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: model_6_SavedModel_format/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmIJQM36QuMP"
      },
      "source": [
        "# Load in a model\n",
        "loaded_model_6_SavedModel_format = tf.keras.models.load_model(\"model_6_SavedModel_format\")"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3SHd6icQ-cY",
        "outputId": "f27cecac-dd73-4cc8-dfb4-01dc794b4bd7"
      },
      "source": [
        "# EAvaluate model in SavedModel format\n",
        "loaded_model_6_SavedModel_format.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 9ms/step - loss: 0.4244 - accuracy: 0.8123\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4244178831577301, 0.8123359680175781]"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thdsw8hHROAb"
      },
      "source": [
        "## Finding the most wrong examples\n",
        "\n",
        "* If our best model still isn't perfect, what example is it getting wrong?\n",
        "* And of these wrong examples which ones is it getting *most* wrong (those with prediction probabilities closest to the opposite class)\n",
        "\n",
        "For example, if a sample should have a label of 0 but our model predicts a prediction probaility of 0.999 (really close to 1) and vice-versa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jgz8w6FcSd42",
        "outputId": "d425dafb-ee6c-4669-fbf8-a96c009ad036"
      },
      "source": [
        "# Download a pretrained model from google storage\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n",
        "!unzip 08_model_6_USE_feature_extractor.zip"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-22 10:59:48--  https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.197.128, 64.233.191.128, 209.85.145.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.197.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 960779165 (916M) [application/zip]\n",
            "Saving to: ‘08_model_6_USE_feature_extractor.zip’\n",
            "\n",
            "08_model_6_USE_feat 100%[===================>] 916.27M  76.0MB/s    in 12s     \n",
            "\n",
            "2021-11-22 11:00:00 (77.5 MB/s) - ‘08_model_6_USE_feature_extractor.zip’ saved [960779165/960779165]\n",
            "\n",
            "Archive:  08_model_6_USE_feature_extractor.zip\n",
            "   creating: 08_model_6_USE_feature_extractor/\n",
            "   creating: 08_model_6_USE_feature_extractor/assets/\n",
            "   creating: 08_model_6_USE_feature_extractor/variables/\n",
            "  inflating: 08_model_6_USE_feature_extractor/variables/variables.data-00000-of-00001  \n",
            "  inflating: 08_model_6_USE_feature_extractor/variables/variables.index  \n",
            "  inflating: 08_model_6_USE_feature_extractor/saved_model.pb  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIjeMxQCTfHk",
        "outputId": "8b2d4d67-6f9b-4976-b9ec-42837e0866a1"
      },
      "source": [
        "# Import previously trained model from google storage\n",
        "model_6_pretrained = tf.keras.models.load_model(\"08_model_6_USE_feature_extractor\")\n",
        "model_6_pretrained.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 10ms/step - loss: 0.4272 - accuracy: 0.8163\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.42723122239112854, 0.8162729740142822]"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJVNM_YTT05G",
        "outputId": "1905718c-aa7f-4d6e-eb4b-e2587a87403c"
      },
      "source": [
        "# make predictions with the loaded model from GS\n",
        "model_6_pretrained_pred_probs = model_6_pretrained.predict(val_sentences)\n",
        "model_6_pretrained_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_pretrained_preds[:10]"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Q12mskwNRsNm",
        "outputId": "0799a1c4-5589-4e43-ec0f-012f8015b875"
      },
      "source": [
        "# Create dataframe with validation sentences, val labels and best performing  model predictions probailities and labels\n",
        "val_df = pd.DataFrame({\"text\": val_sentences,\n",
        "                       \"target\": val_labels,\n",
        "                       \"pred\": model_6_pretrained_preds,\n",
        "                       \"pred_prob\": tf.squeeze(model_6_pretrained_pred_probs)})\n",
        "val_df.head()\n"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.159757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.747162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.988749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@camilacabello97 Internally and externally scr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.196229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Radiation emergency #preparedness starts with ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.707808</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  target  pred  pred_prob\n",
              "0  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0   0.0   0.159757\n",
              "1  FedEx no longer to transport bioterror germs i...       0   1.0   0.747162\n",
              "2  Gunmen kill four in El Salvador bus attack: Su...       1   1.0   0.988749\n",
              "3  @camilacabello97 Internally and externally scr...       1   0.0   0.196229\n",
              "4  Radiation emergency #preparedness starts with ...       1   1.0   0.707808"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiR1bpKZUwVs"
      },
      "source": [
        "# Find the wrong predictions and sort by prediction probabilities\n",
        "most_wrong = val_df[val_df[\"target\"] != val_df[\"pred\"]].sort_values(\"pred_prob\", ascending=False)\n"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1SBahPyYWAcl",
        "outputId": "842604e1-146c-4301-f304-89971037ffc5"
      },
      "source": [
        "most_wrong.head()  # false positives"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.910196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>759</th>\n",
              "      <td>FedEx will no longer transport bioterror patho...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.876982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628</th>\n",
              "      <td>@noah_anyname That's where the concentration c...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.852300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>Ashes 2015: AustraliaÛªs collapse at Trent Br...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.835454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>@AshGhebranious civil rights continued in the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.827213</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  target  pred  pred_prob\n",
              "31   ? High Skies - Burning Buildings ? http://t.co...       0   1.0   0.910196\n",
              "759  FedEx will no longer transport bioterror patho...       0   1.0   0.876982\n",
              "628  @noah_anyname That's where the concentration c...       0   1.0   0.852300\n",
              "209  Ashes 2015: AustraliaÛªs collapse at Trent Br...       0   1.0   0.835454\n",
              "251  @AshGhebranious civil rights continued in the ...       0   1.0   0.827213"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5_hPT7i3W8dq",
        "outputId": "0c11d3ed-a7b2-46a3-99d9-6d507ad614ae"
      },
      "source": [
        "most_wrong.tail() # false negatives"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>411</th>\n",
              "      <td>@SoonerMagic_ I mean I'm a fan but I don't nee...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.043918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>I get to smoke my shit in peace</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.042087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Why are you deluged with low self-image? Take ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>Reddit Will Now QuarantineÛ_ http://t.co/pkUA...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Ron &amp;amp; Fez - Dave's High School Crush https...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.037186</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  target  pred  pred_prob\n",
              "411  @SoonerMagic_ I mean I'm a fan but I don't nee...       1   0.0   0.043918\n",
              "233                    I get to smoke my shit in peace       1   0.0   0.042087\n",
              "38   Why are you deluged with low self-image? Take ...       1   0.0   0.038998\n",
              "244  Reddit Will Now QuarantineÛ_ http://t.co/pkUA...       1   0.0   0.038949\n",
              "23   Ron &amp; Fez - Dave's High School Crush https...       1   0.0   0.037186"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz8LWbRAWMjP"
      },
      "source": [
        "Target labels:    \n",
        "* `0` = not disaster\n",
        "* `1` = disaster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6V6-y0jWCmc",
        "outputId": "a4c39d86-054f-4001-d3fe-b5ba47d41718"
      },
      "source": [
        "# check the false positives (model predicted 1 when should've been 0)\n",
        "for row in most_wrong[:5].itertuples():\n",
        "  _, text, target, pred, pred_prob = row\n",
        "  print(f\"Target: {target}, Pred: {pred}, Prob: {pred_prob}\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"-----\\n\")"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0, Pred: 1.0, Prob: 0.9101957082748413\n",
            "Text:\n",
            "? High Skies - Burning Buildings ? http://t.co/uVq41i3Kx2 #nowplaying\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8769820928573608\n",
            "Text:\n",
            "FedEx will no longer transport bioterror pathogens in wake of anthrax lab mishaps http://t.co/lHpgxc4b8J\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8523001670837402\n",
            "Text:\n",
            "@noah_anyname That's where the concentration camps and mass murder come in. \n",
            " \n",
            "EVERY. FUCKING. TIME.\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8354544639587402\n",
            "Text:\n",
            "Ashes 2015: AustraliaÛªs collapse at Trent Bridge among worst in history: England bundled out Australia for 60 ... http://t.co/t5TrhjUAU0\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8272132873535156\n",
            "Text:\n",
            "@AshGhebranious civil rights continued in the 60s. And what about trans-generational trauma? if anything we should listen to the Americans.\n",
            "\n",
            "-----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMfoaJgIXxlw",
        "outputId": "12bd6257-aa28-43fd-edf7-aa22e8f2ef32"
      },
      "source": [
        "# check the false negatives (model predicted 0 when should've been 1)\n",
        "for row in most_wrong[-5:].itertuples():\n",
        "  _, text, target, pred, pred_prob = row\n",
        "  print(f\"Target: {target}, Pred: {pred}, Prob: {pred_prob}\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"-----\\n\")"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 1, Pred: 0.0, Prob: 0.043918460607528687\n",
            "Text:\n",
            "@SoonerMagic_ I mean I'm a fan but I don't need a girl sounding off like a damn siren\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.04208683967590332\n",
            "Text:\n",
            "I get to smoke my shit in peace\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.03899794816970825\n",
            "Text:\n",
            "Why are you deluged with low self-image? Take the quiz: http://t.co/XsPqdOrIqj http://t.co/CQYvFR4UCy\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.03894948959350586\n",
            "Text:\n",
            "Reddit Will Now QuarantineÛ_ http://t.co/pkUAMXw6pm #onlinecommunities #reddit #amageddon #freespeech #Business http://t.co/PAWvNJ4sAP\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.03718581795692444\n",
            "Text:\n",
            "Ron &amp; Fez - Dave's High School Crush https://t.co/aN3W16c8F6 via @YouTube\n",
            "\n",
            "-----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Cy9AfJAGYdcq",
        "outputId": "1f26a408-cc7e-4e5c-81d6-83515314ac51"
      },
      "source": [
        "test_df"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3258</th>\n",
              "      <td>10861</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3259</th>\n",
              "      <td>10865</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3260</th>\n",
              "      <td>10868</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3261</th>\n",
              "      <td>10874</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3262</th>\n",
              "      <td>10875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3263 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id keyword location                                               text\n",
              "0         0     NaN      NaN                 Just happened a terrible car crash\n",
              "1         2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2         3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3         9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4        11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan\n",
              "...     ...     ...      ...                                                ...\n",
              "3258  10861     NaN      NaN  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...\n",
              "3259  10865     NaN      NaN  Storm in RI worse than last hurricane. My city...\n",
              "3260  10868     NaN      NaN  Green Line derailment in Chicago http://t.co/U...\n",
              "3261  10874     NaN      NaN  MEG issues Hazardous Weather Outlook (HWO) htt...\n",
              "3262  10875     NaN      NaN  #CityofCalgary has activated its Municipal Eme...\n",
              "\n",
              "[3263 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j3oeNysY2me"
      },
      "source": [
        "## Making predictions on the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rFoCtQnZO0D",
        "outputId": "ce967d12-f6e0-41a8-b1fd-ff15c28216ff"
      },
      "source": [
        "# Making predictions on the test dataset and visualizing them\n",
        "test_sentences = test_df[\"text\"].to_list()\n",
        "test_sentences[:5]"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Just happened a terrible car crash',\n",
              " 'Heard about #earthquake is different cities, stay safe everyone.',\n",
              " 'there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all',\n",
              " 'Apocalypse lighting. #Spokane #wildfires',\n",
              " 'Typhoon Soudelor kills 28 in China and Taiwan']"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfW747aLZfPL",
        "outputId": "5d16954f-db64-4a2d-882f-d90d08d224fd"
      },
      "source": [
        "test_samples = random.sample(test_sentences, 10)\n",
        "for test_sample in test_samples:\n",
        "  pred_prob = tf.squeeze(model_6_pretrained.predict([test_sample]))  # our model expects a list as input\n",
        "  pred = tf.round(pred_prob)\n",
        "  print(f\"Pred: {int(pred)}, Prob: {pred_prob}\")\n",
        "  print(f\"Text:\\n{test_sample}\\n\")\n",
        "  print(\"------\\n\")"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred: 0, Prob: 0.06460508704185486\n",
            "Text:\n",
            "Baby you're like lightning in a bottle\n",
            "\n",
            "------\n",
            "\n",
            "Pred: 0, Prob: 0.07505735754966736\n",
            "Text:\n",
            "You cut me open and I keep bleeding. #BleedingLove #LeonaLewis #acapella #singer #canadiansingerÛ_ https://t.co/51pfEIlPNK\n",
            "\n",
            "------\n",
            "\n",
            "Pred: 0, Prob: 0.036669641733169556\n",
            "Text:\n",
            "Trying to get higher in the bathroom at work with my pen b4 I go and demolish my food ??????\n",
            "\n",
            "------\n",
            "\n",
            "Pred: 1, Prob: 0.7723401188850403\n",
            "Text:\n",
            "Yesterday's #hailstorm! #boston #cambridge http://t.co/HbgYpruvO7 http://t.co/SwtgHLibs2\n",
            "\n",
            "------\n",
            "\n",
            "Pred: 0, Prob: 0.365538626909256\n",
            "Text:\n",
            "it doesn't really get much better then summer thunder storms wrapped in a blanket. #icouldsitinthismomentforever\n",
            "\n",
            "------\n",
            "\n",
            "Pred: 1, Prob: 0.6605819463729858\n",
            "Text:\n",
            "@GreenLacey GodsLove &amp; #thankU my sister for RT of NEW VIDEO http://t.co/cybKsXHF7d The Coming Apocalyptic US Earthquake &amp; Tsunami\n",
            "\n",
            "------\n",
            "\n",
            "Pred: 1, Prob: 0.6853218078613281\n",
            "Text:\n",
            "The EFAK would be designed for building occupants once they evacuate and report to their evacuation assembly sites\n",
            "\n",
            "------\n",
            "\n",
            "Pred: 0, Prob: 0.4981151521205902\n",
            "Text:\n",
            "North American Rescue IFAK Refill Trauma Kit with NEW Red Tip Tourniquet IPOK + http://t.co/wrxwCA35EZ http://t.co/Ve0vXVJOkz\n",
            "\n",
            "------\n",
            "\n",
            "Pred: 0, Prob: 0.03648489713668823\n",
            "Text:\n",
            "@McKenzieBlackw1 love you! Sorry for my screams\n",
            "\n",
            "------\n",
            "\n",
            "Pred: 1, Prob: 0.9834675788879395\n",
            "Text:\n",
            "SHOCK REPORT: Muslims Setting Wildfires Across American West...Arson Jihad!\n",
            "\n",
            "http://t.co/92F4nKxjIu\n",
            "\n",
            "------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM46jkIqacIC"
      },
      "source": [
        "## The speed/score tradeoff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JS30Xdogbjf-",
        "outputId": "c2a3f65f-5bcf-48f7-93f0-e4ac7deec531"
      },
      "source": [
        "model_6_results"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.23359580052494,\n",
              " 'f1': 0.8115121319063344,\n",
              " 'precision': 0.812763224356635,\n",
              " 'recall': 0.8123359580052494}"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZC_uNL3Ybotp"
      },
      "source": [
        "# Let's make a function to measure time of prediction\n",
        "import time\n",
        "def pred_timer(model, samples):\n",
        "  '''\n",
        "  Times how long a model takes to make predictions on samples.\n",
        "  '''\n",
        "  start_time = time.perf_counter() # get start time\n",
        "  model.predict(samples)\n",
        "  end_time = time.perf_counter()\n",
        "  total_time = end_time-start_time\n",
        "  time_per_pred = total_time/len(samples)\n",
        "  return total_time, time_per_pred"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQv12doPcgeR",
        "outputId": "44d47a77-bbf3-4be7-a05a-8442bb91cd37"
      },
      "source": [
        "# calculate TF Hub sentence encoder time per pred\n",
        "model_6_total_pred_time, model_6_time_per_pred = pred_timer(model_6_pretrained,\n",
        "                                                            val_sentences)\n",
        "\n",
        "model_6_total_pred_time, model_6_time_per_pred"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.2740327139999863, 0.00035962298425195054)"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Lbw4VIQc2Cu",
        "outputId": "b3c38cb3-248b-4622-a8b5-33adf0b1bac4"
      },
      "source": [
        "# Calculate our baseline model's time per pred\n",
        "baseline_total_pred_time, baseline_time_per_pred = pred_timer(model_0, val_sentences)\n",
        "baseline_total_pred_time, baseline_time_per_pred"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0225961650003228, 2.9653759842943305e-05)"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DICLwfN_deTp",
        "outputId": "caf2ab53-5d8a-4b2d-f5fc-40a26dfde1eb"
      },
      "source": [
        "model_6_pretrained_results = calculate_results(y_true=val_labels,\n",
        "                                               y_pred=model_6_pretrained_preds)\n",
        "model_6_pretrained_results"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.23359580052494,\n",
              " 'f1': 0.8115121319063344,\n",
              " 'precision': 0.812763224356635,\n",
              " 'recall': 0.8123359580052494}"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "6aZWYADcdMtm",
        "outputId": "620b3074-0048-45d6-9bba-16ea5503612c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.scatter(baseline_time_per_pred, baseline_results[\"f1\"], label=\"baseline\")\n",
        "plt.scatter(model_6_time_per_pred, model_6_pretrained_results[\"f1\"], label=\"tf-hub-encoder\")\n",
        "plt.legend()\n",
        "plt.title(\"F1-Score versus time per prediction\")\n",
        "plt.xlabel(\"Time per prediction\")\n",
        "plt.ylabel(\"F1-Score\")"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'F1-Score')"
            ]
          },
          "metadata": {},
          "execution_count": 153
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDiaYu7meS2_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}