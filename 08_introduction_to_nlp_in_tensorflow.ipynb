{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08_introduction_to_nlp_in_tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO9+0bLtZzab7oCM8tLnOp8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kE_wc_sDEOy"
      },
      "source": [
        "# Introduction to NLP fundamentals in Tensorflow\n",
        "\n",
        "NLP has the goal of deriving information out of natural langugae (could be sequences, text or speech).\n",
        "\n",
        "Another common term for NLP problems is seuence to sequence problems (seq2seq).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOc_5Ma5D-Ld"
      },
      "source": [
        "## Check for GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXYWsBcxEDlK"
      },
      "source": [
        "# !nvidia-smi -L"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIGqHyJqEOG9"
      },
      "source": [
        "## Get helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAi0RNY1Ee_W",
        "outputId": "25e12624-d983-4acc-ffc5-bab12d147940"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "# Import series of helper functions for the notebook\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-22 01:18:40--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-11-22 01:18:40 (84.9 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9N7IlrirFbRa"
      },
      "source": [
        "## Get a text dataset\n",
        "\n",
        "The dataset we're going to be using is Kaggle's introduction to NLP dataset (text samples of tweets labelled as disaster or not disaster).\n",
        "\n",
        "Dataset: https://www.kaggle.com/c/nlp-getting-started/data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZICh_MGFmRQ",
        "outputId": "ecfc799a-5841-44e2-f745-43c6639efac5"
      },
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
        "\n",
        "# unzip data\n",
        "unzip_data(\"nlp_getting_started.zip\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-22 01:18:43--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.203.128, 172.253.123.128, 142.250.98.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.203.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2021-11-22 01:18:43 (123 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05OvPk1qHXOG"
      },
      "source": [
        "## Visualizing a text dataset\n",
        "\n",
        "To visualize our text samples, we first have to read them in. One way to do so would be to use python: https://realpython.com/read-write-files-python/\n",
        "\n",
        "Another way to do this is to use pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XXfK1zL6H2nS",
        "outputId": "2431e58a-bc8e-4d0c-871f-0936ceb8c280"
      },
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "train_df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9JqE92UVI2gg",
        "outputId": "bc4854a6-5778-4fdb-8563-0bafc63659b9"
      },
      "source": [
        "train_df[\"text\"][10]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Three people died from the heat wave so far'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4YguOYXYJBrM",
        "outputId": "e6de6c33-b6f6-4399-95f3-35b5a2d6e70f"
      },
      "source": [
        "# shuffle training dataframe\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
        "train_df_shuffled.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "2644  3796  ...      1\n",
              "2227  3185  ...      0\n",
              "5448  7769  ...      1\n",
              "132    191  ...      0\n",
              "6845  9810  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3KlFVsHzJW7_",
        "outputId": "59e3a2ec-2936-406b-fb4d-e314323ce128"
      },
      "source": [
        "train_df_shuffled[\"text\"].iloc[3]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Aftershock back to school kick off was great. I want to thank everyone for making it possible. What a great night.'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PcZgI0xcJs8A",
        "outputId": "76ae02a8-245a-49c2-ccc0-187d5ceb2ab2"
      },
      "source": [
        "# what does the dataframe look like?\n",
        "test_df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7C2cyiUKEQH",
        "outputId": "ef82e939-6f25-46b2-c7e5-f7f0b9acb83e"
      },
      "source": [
        "# how many examples of each class?\n",
        "train_df.target.value_counts()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zr9oPJQ-KPzZ",
        "outputId": "10084a5d-3ba9-4209-8e77-f3739f03c157"
      },
      "source": [
        "# how many total samples?\n",
        "len(train_df), len(test_df)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 3263)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7YQNqtQKrt9",
        "outputId": "8cdeea96-3ae0-4d67-810d-19c6e86a54a0"
      },
      "source": [
        "# Let's visualize some random training examples\n",
        "import random\n",
        "\n",
        "random_index = random.randint(0, len(train_df)-5) # create random indexes not higher than the total number of samples\n",
        "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f\"Target: {target}\", \"(real disaster)\" if target> 0 else \"(not real disaster)\")\n",
        "  print(f\"Text:{text}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0 (not real disaster)\n",
            "Text:It may seem like our fire has been a little burnt out....\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:These fucking police can't touch me  these fuck niggas ain't fucking w me\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:her loyalty mission involves her kicking a shitty nobleman to death???? I love this elven weirdo\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:*screams internally*\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:Turkish troops killed in Kurdish militant 'suicide attack' http://t.co/7cIbxls55f\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xi9TwMVHNdQw"
      },
      "source": [
        "### Split data into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuDdRHiPd8Wb"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12grFQDFeEUu"
      },
      "source": [
        "# Use train_test_split to split training data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                            test_size=0.1,\n",
        "                                                                            random_state=42)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cp4ZfX7jggl",
        "outputId": "dce4e9e7-ef27-4287-8d24-50df886bbb75"
      },
      "source": [
        "# check the lengths\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52DT0b8VjxuY",
        "outputId": "45623d70-3139-48ab-c7da-3a88edf2728d"
      },
      "source": [
        "# check the first 10 samples\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6kDPLMGj7yB"
      },
      "source": [
        "## Converting text into numbers\n",
        "\n",
        "Wheb dealing with a text problem, one of the first thing we have to do is convert text to numbers.\n",
        "\n",
        "There are a few ways to do this, namely:  \n",
        "* **Tokenization** - direct mapping of a token (a token could be a word or a character) to number (text vectorization).\n",
        "* **Embedding** - create a matrix of feature vector for each token (the size of the feature vector can be defined and this embedding can be learned)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlJ-ltH2lzjN"
      },
      "source": [
        "### Text vectorization (Tokenization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "styjNcBJoTR2",
        "outputId": "6660c8df-a0e4-4afa-bd90-244a02418552"
      },
      "source": [
        "train_sentences[:5]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "       'Imagine getting flattened by Kurt Zouma',\n",
              "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "       'Somehow find you and I collide http://t.co/Ee8RpOahPk'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayYDerFyoWql"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "# # Use the default text vectorization parameters\n",
        "# text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabulary (automatically add <OOV>)\n",
        "#                                     standardize=\"lower_and_strip_punctuation\",\n",
        "#                                     split=\"whitespace\",\n",
        "#                                     ngrams=None, # creates groups of n words\n",
        "#                                     output_mode=\"int\",\n",
        "#                                     output_sequence_length=None, # how long do you want your sequences to be?\n",
        "#                                     pad_to_max_tokens=True)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "oU8wVKao95M7",
        "outputId": "44d0a2aa-11f4-44cb-91ad-9f06d1d50e78"
      },
      "source": [
        "train_sentences[0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'@mogacola @zamtriossu i screamed after hitting tweet'"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLTT-SQ79_P6",
        "outputId": "5039e466-82fe-4a87-d108-4f06958ba422"
      },
      "source": [
        "train_sentences[0].split()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@mogacola', '@zamtriossu', 'i', 'screamed', 'after', 'hitting', 'tweet']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alzHAJHi-Nga",
        "outputId": "12522e22-a93e-4f6f-ea71-ae6bc5c6f41b"
      },
      "source": [
        "len(train_sentences[0].split())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3y2CHQX72qoC",
        "outputId": "8b1e3315-8416-4b81-cc29-6178a221195e"
      },
      "source": [
        "# find the average number of tokens (words) in the training tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0wL9Elo-tM6"
      },
      "source": [
        "Average number of tokens (words) in a tweet is 15."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbugBT_L-cvx"
      },
      "source": [
        "# Setup text vectorization variables\n",
        "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
        "max_length = 15  # max length our sequences will be (e.g how many words from a tweet our model will see)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8mQKYqC_zbH"
      },
      "source": [
        "# fit the text vectorizer to training data\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLb5h0-1Abrc",
        "outputId": "5c16a8dc-739d-4f50-d28b-c801219381e5"
      },
      "source": [
        "# create a sample sentence and tokenize it\n",
        "sample_sentence = \"There's a flood in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACqP7GilAzMr",
        "outputId": "605b9966-73df-4371-d1c8-2fe393ed99b4"
      },
      "source": [
        "# Choose a random sentence from the training dataset and tokenize it\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n {random_sentence}\\\n",
        "        \\n\\n Vectorized version:\")\n",
        "text_vectorizer([random_sentence])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            " 'I'm there!' Bride &amp; Groom on mountain cliff edge. Ha Ha just kidding. I WILL NOT EVER be there. Ha Ha - http://t.co/Io9ry1akON        \n",
            "\n",
            " Vectorized version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[  32,   74, 2534,   35, 3803,   11, 1118,  403, 5747, 1844, 1844,\n",
              "          29, 5281,    8,   38]])>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmjFmddCCrsU",
        "outputId": "da512be9-492d-40bd-bd05-27435b7c3abd"
      },
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()  # get all of the unique words in the our training data\n",
        "top_5_words = words_in_vocab[:5] # get the most common words \n",
        "bottom_5_words = words_in_vocab[-5:] # get the least common words\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f'5 most common words: {top_5_words}')\n",
        "print(f\"5 least common words: {bottom_5_words}\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 10000\n",
            "5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NTOqbCAE0bw"
      },
      "source": [
        "[UNK] - unknown token - stands for unknown (word out of the vocabulary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvYKbXC5Eo5Z"
      },
      "source": [
        "### Creating an Embedding using an Embedding Layer\n",
        "\n",
        "To make our embedding, we're going to use Tensorflow's embedding layer.\n",
        "\n",
        "The parameters we care most about for our embedding layer:    \n",
        "* `input_dim` = the size of our vocabulary\n",
        "* ` output_dim` = the size of the output embedding vector, for example, a value of 100 would mean each token gets represented by a vector 100 long\n",
        "* `input_length` = length of the sequences being passed to the embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpPbkWIhH0uD",
        "outputId": "d94c5396-7471-45ae-fad4-e33a624eab45"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
        "                             output_dim=128,\n",
        "                             input_length=max_length)\n",
        "\n",
        "embedding"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.embeddings.Embedding at 0x7f85f22e2990>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_ZGMsB7JpZc",
        "outputId": "33206e2d-a003-448e-b201-5a180051d3c0"
      },
      "source": [
        "# Get a random sentence from the training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n {random_sentence}\\\n",
        "        \\n\\nEmbedded version:\")\n",
        "\n",
        "# embed the random sentence (turn positive indexes into dense vectors of fixed size)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            " Schools in Western Uganda still Burning down Buildings during Strikes....Strikes in Western Uganda always Lit literally..        \n",
            "\n",
            "Embedded version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 0.00994015,  0.00577831, -0.00043528, ...,  0.04774579,\n",
              "          0.01212071, -0.0034212 ],\n",
              "        [ 0.00211239, -0.03780458,  0.04884586, ...,  0.03071113,\n",
              "          0.03307253,  0.00030943],\n",
              "        [-0.00271506,  0.04528258, -0.04335169, ..., -0.01416766,\n",
              "         -0.01951832, -0.04870909],\n",
              "        ...,\n",
              "        [ 0.04028371,  0.03936007,  0.03438186, ..., -0.03889229,\n",
              "         -0.01814235,  0.02407361],\n",
              "        [-0.00980448, -0.00040821,  0.00125802, ...,  0.04625118,\n",
              "          0.04932446,  0.01113433],\n",
              "        [-0.04881958,  0.00945355,  0.04712505, ...,  0.01100018,\n",
              "         -0.02779353,  0.03544778]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5kXKSQEKdXy",
        "outputId": "48249190-0c33-4626-d137-737bcd0edc65"
      },
      "source": [
        "# check out a single token's embedding\n",
        "sample_embed[0][0], sample_embed[0][0].shape, random_sentence.split()[0]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([ 9.94014740e-03,  5.77831268e-03, -4.35281545e-04,  1.05892643e-02,\n",
              "         1.24777928e-02, -1.79928541e-02,  1.58855952e-02,  7.69805908e-03,\n",
              "        -1.29309520e-02,  4.85724546e-02, -3.89259681e-02,  1.73329003e-02,\n",
              "         2.91436911e-03,  1.55113824e-02,  2.26318836e-03,  4.05368954e-03,\n",
              "        -7.92622566e-03,  3.39297093e-02,  1.21985301e-02,  4.95840646e-02,\n",
              "        -4.64603417e-02, -1.60421506e-02,  4.12191488e-02, -3.44217941e-03,\n",
              "        -2.41199732e-02, -3.00542470e-02,  7.89222866e-03, -4.04802337e-02,\n",
              "         5.02648205e-03, -3.03645022e-02, -4.00644056e-02,  1.77922510e-02,\n",
              "         2.52030604e-02, -2.67759208e-02, -2.18204390e-02, -3.08597926e-02,\n",
              "         2.53888480e-02, -4.47162278e-02, -3.45362313e-02, -4.90672700e-02,\n",
              "        -3.81481051e-02, -4.34619784e-02, -1.70738809e-02,  3.93620394e-02,\n",
              "         4.01688330e-02, -1.12074837e-02,  6.40075281e-03,  7.45686144e-03,\n",
              "        -1.29419789e-02,  1.39381997e-02,  3.91418673e-02, -7.37762451e-03,\n",
              "        -6.07136637e-03, -1.19485855e-02,  3.58581208e-02, -2.25699898e-02,\n",
              "        -3.33122611e-02,  3.75117697e-02,  3.71284597e-02, -5.89787960e-04,\n",
              "         1.34452097e-02, -9.25101340e-04, -6.95110485e-03,  4.28717248e-02,\n",
              "        -4.68563326e-02, -3.69002335e-02, -4.95589152e-02, -4.94419001e-02,\n",
              "         1.01591721e-02, -4.08380106e-03, -3.88538726e-02, -2.53465027e-03,\n",
              "        -7.51886517e-03, -3.04698944e-03, -2.53620744e-02,  2.45030969e-03,\n",
              "         4.11827825e-02,  2.50089653e-02, -8.69449228e-03,  2.48129480e-02,\n",
              "         4.67973016e-02, -1.34261958e-02,  9.26071405e-03,  9.20053571e-03,\n",
              "         1.07122883e-02,  3.66715230e-02,  2.59996690e-02, -1.53860338e-02,\n",
              "        -2.45917682e-02,  2.50560157e-02, -1.78319439e-02,  4.29465063e-02,\n",
              "         4.92945947e-02, -1.06779709e-02, -4.60483544e-02,  8.76591355e-03,\n",
              "        -2.37827785e-02, -2.23202351e-02, -2.60295272e-02,  1.54259913e-02,\n",
              "         4.28156517e-02, -3.50130200e-02, -5.85429370e-05,  1.29060410e-02,\n",
              "        -3.12424824e-03, -6.86228275e-03,  4.19993438e-02,  7.57962465e-03,\n",
              "         1.85514428e-02, -3.48772779e-02,  4.27532084e-02,  2.84561627e-02,\n",
              "         3.21677811e-02,  2.38965414e-02,  1.55542046e-03, -4.08601537e-02,\n",
              "        -2.06179973e-02,  4.70764674e-02, -2.69792434e-02, -3.59726064e-02,\n",
              "         1.92520060e-02, -7.38640875e-03, -3.73215191e-02, -2.49574538e-02,\n",
              "        -1.12174042e-02,  4.77457903e-02,  1.21207125e-02, -3.42119858e-03],\n",
              "       dtype=float32)>, TensorShape([128]), 'Schools')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFYIT7bYLG68"
      },
      "source": [
        "## Modelling a text dataset\n",
        "\n",
        "Now we've got a way to turn our tetxt sequences into numbers, it's time to start building a series of modelling experiments.\n",
        "\n",
        "Let;s start with a baseline and move on from there.\n",
        "\n",
        " * Model 0: Naive Bayes (baseline) \n",
        " * Model 1: Feed-forward neural network\n",
        " * Model 2: LSTM model (RNN)\n",
        " * Model 3: GRU model (RNN)\n",
        " * Model 4: Bidirectional-LSTM model (RNN)\n",
        " * Model 5: 1D Convolutional Neural network (CNN)\n",
        " * Model 6: Tensorflow Hub pretrained feature extractor (using transfer learning for NLP)\n",
        " * Model 7: Same as model 6 with 10% of training data\n",
        "\n",
        "We will use the standard steps in modelling with tensorflow:    \n",
        "* Create a model\n",
        "* Build a model\n",
        "* Fit the model\n",
        "* Evaluate the model\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT7fx98DMjNE"
      },
      "source": [
        "### Model 0: Getting a Baseline Model\n",
        "\n",
        "As with all machine elarning modelling experiments, it's important to create a baseline model so you've gto a benchmark for future experiments to build upon.\n",
        "\n",
        "To create our baseline, we'll sue Sklearn's Multinomial Naive Bayes using the TF-IDF formula to convert our words to numbers.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5G5fcyWjdG88",
        "outputId": "13eab712-7de6-4062-cafa-38d341109775"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
        "                    (\"clf\", MultinomialNB()) # model the text\n",
        "])\n",
        "\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqf5Rop-eARm",
        "outputId": "3c322d15-0f83-4a5d-ec64-242d29a80af0"
      },
      "source": [
        "# evaluate our baseline model\n",
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"Our baseline model achieves an accuracy of :{baseline_score*100:.2f}%\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our baseline model achieves an accuracy of :79.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ro964ZZfefBA",
        "outputId": "4ad3f6ed-7682-4d8e-e8a7-7355797a46d8"
      },
      "source": [
        "train_df.target.value_counts() # slightly imbalanced classes"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3bgCs5CepS1",
        "outputId": "15c41ee9-bf02-4e95-9ed4-fd780cf1a687"
      },
      "source": [
        "# make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:10]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1qeRO9Ce1TB"
      },
      "source": [
        "### Creating an evaluation function for our model experiments\n",
        "\n",
        "Let's create a function to compare our model's predictions with the truth label using the following metrics:   \n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJdgW8Qmf0uS"
      },
      "source": [
        "# Function to evaluate: accuracy , precision, recall , f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  '''\n",
        "  Calculates model accuracy, precision, recall and f1-score of a binary classification model.\n",
        "  '''\n",
        "  # calculat model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred)*100\n",
        "  # calculate model precision, recall and f1-score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                   \"precision\": model_precision,\n",
        "                   \"recall\": model_recall,\n",
        "                   \"f1\": model_f1}\n",
        "  return model_results "
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uM_EP9FyBLkY",
        "outputId": "d1071078-3dc8-40cb-eb20-7279b2a0e55e"
      },
      "source": [
        "# get baseline results\n",
        "baseline_results = calculate_results(y_true = val_labels,\n",
        "                                     y_pred = baseline_preds)\n",
        "baseline_results"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6q-_UsUPBZRl"
      },
      "source": [
        "### Model 1: A simple dense model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gvc5YrMFJpJ"
      },
      "source": [
        "# Create a tensorboard callback (need to create a new one for each model)\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create a directory to save tensorboard logs\n",
        "SAVE_DIR = \"model_logs\"\n",
        "\n",
        "# Build the model with functional API\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string) # inputs are 1-dimensional strings\n",
        "x = text_vectorizer(inputs) # turn the input text into numbers\n",
        "x = embedding(x)  # create an embedding of numberized inputs\n",
        "x = layers.GlobalAveragePooling1D()(x)  # condense the feature vector for each token to one vector\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)  # create the output layer, want binary outputs so use sigmoid activation function\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\")"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICsa8Ei9Gh3d",
        "outputId": "eb389924-063b-4fdc-9079-75f87082e029"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGvM1kuOJktO",
        "outputId": "e8d2d912-6ad8-4e0e-db8a-3b19ff0fc331"
      },
      "source": [
        "# Compile the model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# fit the model\n",
        "model_1_history = model_1.fit(x=train_sentences,\n",
        "                              y=train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                     experiment_name=\"model_1_dense\")])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_1_dense/20211122-011845\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 4s 16ms/step - loss: 0.6117 - accuracy: 0.6866 - val_loss: 0.5376 - val_accuracy: 0.7493\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.4428 - accuracy: 0.8145 - val_loss: 0.4725 - val_accuracy: 0.7861\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.3479 - accuracy: 0.8594 - val_loss: 0.4609 - val_accuracy: 0.7940\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.2861 - accuracy: 0.8910 - val_loss: 0.4622 - val_accuracy: 0.7900\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.2387 - accuracy: 0.9123 - val_loss: 0.4802 - val_accuracy: 0.7900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FVMHTOXK8ya",
        "outputId": "d75fe822-5af2-4b04-f376-c1330f61e322"
      },
      "source": [
        "# check the results\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7900\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4801863133907318, 0.7900262475013733]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lz1K4lVWNq6q",
        "outputId": "7817be50-98cc-4985-950a-b9cd7a1a58d0"
      },
      "source": [
        "#make some predictions and evaluate those\n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(762, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__TAaqlDOG9Z",
        "outputId": "088f664e-989d-413b-b563-ae81f1ff9760"
      },
      "source": [
        "# look at a single prediction\n",
        "model_1_pred_probs[0]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.335145], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhSWFqqAOKv_",
        "outputId": "8f2e5190-2a1e-4c6d-d8f1-77873b485958"
      },
      "source": [
        "# Look  at the first 10 predictions\n",
        "model_1_pred_probs[:10]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.335145  ],\n",
              "       [0.83417773],\n",
              "       [0.9980501 ],\n",
              "       [0.08792666],\n",
              "       [0.10919306],\n",
              "       [0.9329672 ],\n",
              "       [0.9141898 ],\n",
              "       [0.99379194],\n",
              "       [0.96276736],\n",
              "       [0.22897881]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXHYCisy_Ocy",
        "outputId": "279ddbc1-cba4-4dd1-8866-35b1bcfbe879"
      },
      "source": [
        "# convert model prediction probabilities to label format\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
        "model_1_preds[:10]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GP7ehTMf_tqN",
        "outputId": "58863e16-332c-4f78-d539-74540045812b"
      },
      "source": [
        "# calculate model_1 results\n",
        "model_1_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.00262467191601,\n",
              " 'f1': 0.7866259949990327,\n",
              " 'precision': 0.7964718621790533,\n",
              " 'recall': 0.7900262467191601}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bSwjYt_AFap",
        "outputId": "95945200-b5cf-461b-89c0-01ebd782c587"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dMvXvPxAG2h",
        "outputId": "07819e8c-51a1-4f82-87cb-a18b8ef444fb"
      },
      "source": [
        "import numpy as np\n",
        "np.array(list(model_1_results.values())) >  np.array(list(baseline_results.values()))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C47EvWAKBQYf"
      },
      "source": [
        "Comparing results shows that baseline model outperforms our first deep leanring based dense model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slk7X5DgA03F"
      },
      "source": [
        "## Visualizing learned embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CocykaRtB2FE"
      },
      "source": [
        "# Get the vocabulary from the text vectorization layer\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_412_vTCO_5",
        "outputId": "737d04d7-86f3-4767-bf49-1ddcf3b2e4c6"
      },
      "source": [
        "len(words_in_vocab)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QthdATdYCQCc",
        "outputId": "e7086bde-f4ca-4280-9bce-83ecf8a7052b"
      },
      "source": [
        "# first 10 most common words\n",
        "words_in_vocab[:10]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is']"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xr565Nt4CYhp",
        "outputId": "99614686-2efc-4f3d-9be8-ffe02953b341"
      },
      "source": [
        "max_vocab_length"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6NlW5BLCiNS",
        "outputId": "8bdf8783-1d1f-4f2a-97a8-a22c01474cc7"
      },
      "source": [
        "# Model 1 summary\n",
        "model_1.summary()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2h1X9btACuxY",
        "outputId": "d83db1c9-d94d-401b-9bf5-78039e6bf022"
      },
      "source": [
        "# get the weight matrix of embedding layer\n",
        "# (these are the numerical representations of each token in our training data which have been learned for 5 epochs)\n",
        "embed_weights = model_1.get_layer(\"embedding\").get_weights()[0]\n",
        "embed_weights"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.01823394, -0.06905591,  0.00959345, ...,  0.01379115,\n",
              "        -0.02526248,  0.01233402],\n",
              "       [-0.009679  , -0.04669121, -0.02075852, ...,  0.01120809,\n",
              "         0.00658702,  0.01890875],\n",
              "       [ 0.02131985,  0.00671595,  0.02653384, ...,  0.04322812,\n",
              "         0.02514545,  0.02300458],\n",
              "       ...,\n",
              "       [ 0.04706607, -0.0005859 , -0.04014157, ..., -0.02090134,\n",
              "        -0.01535139, -0.00048393],\n",
              "       [ 0.03409407, -0.03720106, -0.01192651, ...,  0.06868954,\n",
              "         0.009566  ,  0.03031763],\n",
              "       [ 0.05853991, -0.03419592, -0.02397197, ...,  0.07778879,\n",
              "         0.04682536,  0.114053  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sp63iproFU2o",
        "outputId": "67d9a167-99ce-4884-87ad-e2baefed643b"
      },
      "source": [
        "print(embed_weights.shape) # same size as vocab size and embedding_dim (output_dim of embedding layer)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRSwuPlcGSff"
      },
      "source": [
        "Now we've got the embedding matrix our model has learned to represent our tokens, let's see how we can visualize it:    \n",
        "\n",
        "To do so, Tensorflow has a handy tool called **Projector**: http://projector.tensorflow.org/\n",
        "\n",
        "And TensorFlow also has an incredible guide on **word embeddings** themselves: https://www.tensorflow.org/text/guide/word_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOckRkE7FX1b"
      },
      "source": [
        "# # create embedding files (we've got this from Tensorflow's word embeddings documentation)\n",
        "# import io\n",
        "# out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "# out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "# for index, word in enumerate(words_in_vocab):\n",
        "#   if index == 0:\n",
        "#     continue  # skip 0, it's padding.\n",
        "#   vec = embed_weights[index]\n",
        "#   out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "#   out_m.write(word + \"\\n\")\n",
        "# out_v.close()\n",
        "# out_m.close()"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cm0RPo7LdY4N"
      },
      "source": [
        "# # Download files from colab to upload to projector\n",
        "# try:\n",
        "#   from google.colab import files\n",
        "#   files.download('vectors.tsv')\n",
        "#   files.download('metadata.tsv')\n",
        "# except Exception:\n",
        "#   pass"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "symtnafJh3qs"
      },
      "source": [
        "## Recurrent Neural Networks (RNN's)\n",
        "\n",
        "RNNs are useful for sequence data.\n",
        "\n",
        "The premise of a recurrent neural network is to use the representation of a previous input to aid the representation of a later input.\n",
        "\n",
        "- MIT deep learning: http://introtodeeplearning.com/\n",
        "- Andrej Karpathy's blog post: http://karpathy.github.io/2015/05/21/rnn-effectiveness/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReAiU9Rregxr"
      },
      "source": [
        "### Model 2 - LSTM\n",
        "\n",
        "LSTM stands for **Long short term memory** (one of the most popular LSTM cells)\n",
        "\n",
        "Our structure of an RNN typically looks like this:    \n",
        "```\n",
        "Input (text) -> Tokenize -> Embedding -> Layers (RNN/Dense) -> Output (label probability)\n",
        "``` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2X5MgU1LmA6N",
        "outputId": "30811402-b037-4e6b-90ed-1cdba0de0e0b"
      },
      "source": [
        "# Create an LSTM model\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "print(x.shape)\n",
        "x = layers.LSTM(64, return_sequences=True)(x) # when you're stacking RNN cells together, you need to return_sequences = true  \n",
        "print(x.shape)\n",
        "x = layers.LSTM(64)(x)\n",
        "# print(x.shape)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x)\n",
        "# print(x.shape)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\") "
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 15, 128)\n",
            "(None, 15, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzOgNQIKnyxj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ac73775-f94a-454b-db9e-0416f0b12fd2"
      },
      "source": [
        "# Get a summary\n",
        "model_2.summary()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 15, 64)            49408     \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 64)                33024     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,362,497\n",
            "Trainable params: 1,362,497\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OKpTE3PPvud"
      },
      "source": [
        "# compile the model\n",
        "model_2.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzQ65HcsQEvV",
        "outputId": "b8eb672e-f067-45b9-d384-34de6d4dc86d"
      },
      "source": [
        "# fit the model\n",
        "model_2_history = model_2.fit(x=train_sentences,\n",
        "                              y=train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,experiment_name=\"model_2_LSTM\")])"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_LSTM/20211122-012916\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 12s 41ms/step - loss: 0.2186 - accuracy: 0.9244 - val_loss: 0.5665 - val_accuracy: 0.7874\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.1622 - accuracy: 0.9409 - val_loss: 0.7164 - val_accuracy: 0.7782\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.1327 - accuracy: 0.9494 - val_loss: 0.6939 - val_accuracy: 0.7717\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.1052 - accuracy: 0.9577 - val_loss: 0.9736 - val_accuracy: 0.7690\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0824 - accuracy: 0.9664 - val_loss: 1.2700 - val_accuracy: 0.7717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JtO5SHfQj7L",
        "outputId": "0b2bcc1b-260a-4313-aba8-325916ee1830"
      },
      "source": [
        "# Make predictions with LSTM model\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs[:10]"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.0907989e-04],\n",
              "       [4.4239292e-01],\n",
              "       [9.9991542e-01],\n",
              "       [3.2060742e-03],\n",
              "       [1.1440077e-04],\n",
              "       [9.9985641e-01],\n",
              "       [9.4922984e-01],\n",
              "       [9.9993193e-01],\n",
              "       [9.9992597e-01],\n",
              "       [6.3492900e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Im2oiiJsQ6Ij",
        "outputId": "3921caff-4b2f-4481-e5a3-ed68f7341c0d"
      },
      "source": [
        "# Convert model 2 pred probs to labels\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_P9vY4xRK9R"
      },
      "source": [
        "# Calculate model 2 results\n",
        "model_2_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_2_preds)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpTE5aq5RXjd",
        "outputId": "cea745cf-0742-405b-f7ff-4f8ac8c88db2"
      },
      "source": [
        "model_2_results"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.16535433070865,\n",
              " 'f1': 0.7693184984034235,\n",
              " 'precision': 0.7738402637184817,\n",
              " 'recall': 0.7716535433070866}"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMBHLvq5RZSZ",
        "outputId": "6403ee0c-2270-4da8-f22e-c672338fe4e1"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yxLVPdkRb2-"
      },
      "source": [
        "### Model 3: GRU\n",
        "\n",
        "Another popular and effective RNN component is the **GRU** or **gated recurrent unit**.\n",
        "\n",
        "The GRU cell has similar features to an LSTM cell but has less parameters.\n",
        "\n",
        "Resource: https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUhuV6FvSK_n"
      },
      "source": [
        "# Build an RNN using the GRU cell\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# x = layers.GRU(64, return_sequences=True)(x) # if you want to stack RNN layers on top of each other, you need return_sequences=True\n",
        "# x = layers.LSTM(64, return_sequences=True)(x)\n",
        "x = layers.GRU(64)(x)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlj7JHovVM_9",
        "outputId": "7f012628-210e-4c10-8132-860043104764"
      },
      "source": [
        "# get a summary\n",
        "model_3.summary()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_12 (InputLayer)       [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " gru_10 (GRU)                (None, 64)                37248     \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYsTB6WKVpvx"
      },
      "source": [
        "# compile the model\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqKQJlAUWuaF",
        "outputId": "99f5fbe0-b8ae-4fbe-bd01-f505501c59b7"
      },
      "source": [
        "# fit the model\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"model_3_GRU\")])"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_3_GRU/20211122-015729\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 9s 31ms/step - loss: 0.1599 - accuracy: 0.9365 - val_loss: 0.7541 - val_accuracy: 0.7822\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 6s 27ms/step - loss: 0.0865 - accuracy: 0.9675 - val_loss: 0.7837 - val_accuracy: 0.7795\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 6s 27ms/step - loss: 0.0704 - accuracy: 0.9720 - val_loss: 0.7928 - val_accuracy: 0.7651\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 6s 27ms/step - loss: 0.0616 - accuracy: 0.9730 - val_loss: 1.2863 - val_accuracy: 0.7651\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 6s 27ms/step - loss: 0.0513 - accuracy: 0.9778 - val_loss: 1.2607 - val_accuracy: 0.7677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41hTTx6bXGgy",
        "outputId": "758b4c35-448f-46ea-8449-c4e0bbfe2d10"
      },
      "source": [
        "# make some predictions with our gru model\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs[:10]"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.7517753e-01],\n",
              "       [7.2118533e-01],\n",
              "       [9.9988776e-01],\n",
              "       [2.3518619e-01],\n",
              "       [7.0693728e-05],\n",
              "       [9.9969041e-01],\n",
              "       [5.8729303e-01],\n",
              "       [9.9994457e-01],\n",
              "       [9.9990779e-01],\n",
              "       [8.5242534e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1Ct7sd3XSKK",
        "outputId": "8e6166ef-fd98-48ff-f9b7-6b326dfa1c89"
      },
      "source": [
        "# convert model 3 pred probs to labels\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiJuyUWVXgCw",
        "outputId": "a744c8fc-4d53-4dae-b5ad-6dc8f42d747c"
      },
      "source": [
        "# calculate model 3 results\n",
        "model_3_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_3_preds)\n",
        "model_3_results"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.77165354330708,\n",
              " 'f1': 0.7662770891654436,\n",
              " 'precision': 0.7681410880728078,\n",
              " 'recall': 0.7677165354330708}"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlwVOyG-XsQ-",
        "outputId": "37bc6b7d-5bc5-44f6-be60-8cec9e5e4a50"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaQSTxN5XuIX"
      },
      "source": [
        "### Model 4: Bidirectional RNN\n",
        "\n",
        "Normal RNN's go from left to right however, bidirectional RNN goes from right to left as well as left to right."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vt_o-WAfY7WJ"
      },
      "source": [
        "# build a bidirectional RNN\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_bidirectional\")"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzTHUwErZ17d",
        "outputId": "96247866-3023-4dd9-e1ee-d9890c355da3"
      },
      "source": [
        "# Get a summary\n",
        "model_4.summary()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_bidirectional\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_14 (InputLayer)       [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 128)              98816     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiwRv-bnZ7Ag"
      },
      "source": [
        "# compile the model\n",
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmWxNAsibXdN",
        "outputId": "85bdaaf1-6709-432d-8bad-359d47750131"
      },
      "source": [
        "# fit the model\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\"model_4_bidirectional\")])"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_4_bidirectional/20211122-021806\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 12s 41ms/step - loss: 0.1032 - accuracy: 0.9702 - val_loss: 1.0089 - val_accuracy: 0.7756\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0514 - accuracy: 0.9784 - val_loss: 1.2971 - val_accuracy: 0.7703\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0454 - accuracy: 0.9784 - val_loss: 1.4176 - val_accuracy: 0.7559\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0434 - accuracy: 0.9806 - val_loss: 1.2670 - val_accuracy: 0.7690\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0397 - accuracy: 0.9816 - val_loss: 1.4282 - val_accuracy: 0.7703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhbwT_Jkb0WR",
        "outputId": "04e2f2c0-08bc-4b3c-8f03-3c8c4a191573"
      },
      "source": [
        "# make predictions with bidirectional model\n",
        "model_4_pred_probs = model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.3440549e-03],\n",
              "       [7.9761732e-01],\n",
              "       [9.9997306e-01],\n",
              "       [2.5411865e-01],\n",
              "       [1.3346498e-05],\n",
              "       [9.9910545e-01],\n",
              "       [6.7561316e-01],\n",
              "       [9.9998522e-01],\n",
              "       [9.9997926e-01],\n",
              "       [9.9062079e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EEzpAsocCdt",
        "outputId": "5e7f6d6a-17aa-447e-df50-f60008c27848"
      },
      "source": [
        "# convert pred probs to labels\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DK8dkDDcJri",
        "outputId": "61277cc4-ec7e-450f-e916-3ab2b683b6e5"
      },
      "source": [
        "# calculate the results of bidirectional model\n",
        "model_4_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_4_preds)\n",
        "model_4_results"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.03412073490814,\n",
              " 'f1': 0.7684486602580174,\n",
              " 'precision': 0.7715893693867238,\n",
              " 'recall': 0.7703412073490814}"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyjLsS13cZsy"
      },
      "source": [
        "## Convolutional Neural Networks for Text ( and other types of sequences)\n",
        "\n",
        "CNNs are typically used for images but images are 2D (height*width)..however text data is 1D.\n",
        "\n",
        "Conv2D is used for image data but Conv1D can be used for text.\n",
        "\n",
        "The typical structure of a Conv1D model fr sequences:    \n",
        "\n",
        "```\n",
        "Input (text) -> Tokenization -> Embedding -> Layer(s) (typically Conv1D + Pooling) -> Ouputs (class probabilities)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkThbjASdYe7"
      },
      "source": [
        "### Model 5: Conv1D\n",
        "\n",
        "For different explanations of parameters, see:    \n",
        "* https://poloclub.github.io/cnn-explainer/\n",
        "* Difference between same and valid padding: stackoverflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vElAN7tOeWT-",
        "outputId": "7fabd358-2586-4f5b-ffec-2fbe16976820"
      },
      "source": [
        "# Test out our embedding layer, Conv1D layer and max pooling\n",
        "from tensorflow.keras import layers\n",
        "embedding_test = embedding(text_vectorizer([\"this is a test sentence\"])) # turn target sequence into embedding\n",
        "conv_1d = layers.Conv1D(filters=64,\n",
        "                        kernel_size=5, # this is also refereed to as  ngram of 5 (it looks at 5 words at a time)\n",
        "                        activation=\"relu\",\n",
        "                        padding=\"valid\") #(output is smaller than the input shape with \"valid\")\n",
        "conv_1d_output = conv_1d(embedding_test) # pass test embedding through conv1d layer\n",
        "max_pool = layers.GlobalMaxPool1D()\n",
        "max_pool_output = max_pool(conv_1d_output)  # equivalent to 'get the most important feature' or 'get the feature with the highest value'\n",
        "\n",
        "\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape\n"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 11, 64]), TensorShape([1, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWe-2vS5gFLw"
      },
      "source": [
        "# embedding_test"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mX1fFWhiY7H"
      },
      "source": [
        "# conv_1d_output"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFf4XXgCicJo"
      },
      "source": [
        "# max_pool_output"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEc3J9ERiq3N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}