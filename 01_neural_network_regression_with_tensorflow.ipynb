{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_neural_network_regression_with_tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNr3xIZg5rNILBgkm06k0kU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjnOl-nfgmrk"
      },
      "source": [
        "# Introduction to Regression with Neural Networks in Tensorflow\n",
        "\n",
        "There are many definitions for a regression problem but in our case, we're going to simplify it: predicting a numerical variable based on some other combination of variables, even shorter...predicting a number."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhqaonFyig1i",
        "outputId": "e0fec502-9d00-4a5d-c9f0-f12dbe6cf304"
      },
      "source": [
        "# Import tensorflow\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjPelaN1CbCs"
      },
      "source": [
        "## Create data to view and fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "W6347ZrjHi2S",
        "outputId": "50077e4f-2f8c-4569-e1d7-64a8c1c5754d"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create features\n",
        "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
        "\n",
        "# Create labels\n",
        "y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
        "\n",
        "# Visualize it\n",
        "plt.scatter(X, y);"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJorEUo4IJ-P",
        "outputId": "1309a3de-17c1-4f60-bbda-fde0dff47107"
      },
      "source": [
        "y == X+10"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdzcKt37IjFm"
      },
      "source": [
        "## Input and Output Shapes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZPX1CWaIt2s",
        "outputId": "2506c0d4-4ab1-4f04-c9b8-019375e2c08a"
      },
      "source": [
        "# Create a demo tensor for our housing price prediction problem\n",
        "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n",
        "house_price = tf.constant([939700])\n",
        "house_info, house_price"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
              " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46gIREH1JZUK",
        "outputId": "f060d1b2-f623-463c-f5ca-104a86185647"
      },
      "source": [
        "X[0], y[0]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-7.0, 3.0)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxUblNX7JL2w",
        "outputId": "0b087412-71e8-42d9-c4d5-ccaea25c7b25"
      },
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape\n",
        "input_shape, output_shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((), ())"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Cp2GamxJqhw",
        "outputId": "457b667f-7d12-46cb-cdbb-cb0b1a7afb7d"
      },
      "source": [
        "X[0].ndim"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-qdHbgwJ3pD"
      },
      "source": [
        "As it is 0 dimensional i.e scalar, hence it has no shape.\n",
        "\n",
        "We want to predict one 'y' value based on one 'X' value.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4H0xZuYPJ81h",
        "outputId": "d1a2ca6c-af2a-4268-cebf-83da3ff716ad"
      },
      "source": [
        "# Turn numpy arrays into tensors\n",
        "\n",
        "X = tf.constant(X)\n",
        "y = tf.constant(y)\n",
        "X, y"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wf3A5NpVKdo_",
        "outputId": "22a809ea-a6c5-4df5-abc0-90dfa6d1c363"
      },
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape\n",
        "input_shape, output_shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([]), TensorShape([]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kot9O_qZKoVl"
      },
      "source": [
        "## Steps in modelling with Tensorflow\n",
        "\n",
        "1. **Creating a model** - define the input and output layers, as well as the hidden layers of a deep learning model.\n",
        "2. **Compiling a model** - define the loss function (in other words, the function which tells our model how to improve the patterns it's learning) and evaluation metrics (what we can use to interpret the performance of our model).\n",
        "3. **Fitting a model** - letting the model try to find patterns between X and y (features and labels).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2gB1lJtKuJG",
        "outputId": "5ca48ce8-9256-4783-cd93-22d34f4c9838"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model using the sequential API\n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss = tf.keras.losses.mae, #mae is mean absolute error\n",
        "              optimizer = tf.keras.optimizers.SGD(), #SGD - stochastic gradient descent\n",
        "              metrics = [\"mae\"])\n",
        "\n",
        "# 3.Fit the model\n",
        "model.fit(X, y, epochs=5)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 496ms/step - loss: 11.5048 - mae: 11.5048\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.3723 - mae: 11.3723\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.2398 - mae: 11.2398\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 11.1073 - mae: 11.1073\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.9748 - mae: 10.9748\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6c40d9d0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OppV5Y1EOukz",
        "outputId": "56c4156c-1f00-40d0-eb0b-c65ddb63b9f0"
      },
      "source": [
        "# Check out X and y\n",
        "X, y"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-B5mEXuTPdod",
        "outputId": "1372cb40-bc59-4405-8b22-97e2a27bd5db"
      },
      "source": [
        "# Try and make a prediction using trained model\n",
        "y_pred = model.predict([17.0])\n",
        "y_pred"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12.716021]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVrsYDx6PkJF"
      },
      "source": [
        "##Improving our model\n",
        "\n",
        "We can improve our model by altering the steps we took to create ou rmodel:\n",
        "\n",
        "1. **Creating a model** - Here we migth add more layers, increase the number of hidden units (also called neurons) withing each of the hidden layers, change the activate function of each layer.\n",
        "2. **Compiling a model** - Here we might change the optimization function or perhaps th **learning rate** of the optimization function.\n",
        "3. **Fitting a model** - here we might fit a model for more **epochs** (leave it training for longer) or on more data (give the model more examples to learn from)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Gg-c9tDP2il",
        "outputId": "0994c38b-ec39-4eba-f098-7ddce268dbd5"
      },
      "source": [
        "# Let's rebuild our model\n",
        "\n",
        "# 1. Create the model\n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2.Compile the model\n",
        "model.compile(loss = tf.keras.losses.mae,\n",
        "              optimizer = tf.keras.optimizers.SGD(),\n",
        "              metrics =[\"mae\"])\n",
        "\n",
        "# 3.Fit the model\n",
        "model.fit(X, y, epochs=100)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 11.2219 - mae: 11.2219\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.0894 - mae: 11.0894\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 10.9569 - mae: 10.9569\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 10.8244 - mae: 10.8244\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 10.6919 - mae: 10.6919\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 10.5594 - mae: 10.5594\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 10.4269 - mae: 10.4269\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.2944 - mae: 10.2944\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.1619 - mae: 10.1619\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 10.0294 - mae: 10.0294\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 9.8969 - mae: 9.8969\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.7644 - mae: 9.7644\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.6319 - mae: 9.6319\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.4994 - mae: 9.4994\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.3669 - mae: 9.3669\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.2344 - mae: 9.2344\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.1019 - mae: 9.1019\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.9694 - mae: 8.9694\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.8369 - mae: 8.8369\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.7044 - mae: 8.7044\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.5719 - mae: 8.5719\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.4394 - mae: 8.4394\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.3069 - mae: 8.3069\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.1744 - mae: 8.1744\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.0419 - mae: 8.0419\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.9094 - mae: 7.9094\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.7769 - mae: 7.7769\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.6444 - mae: 7.6444\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.5119 - mae: 7.5119\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.3794 - mae: 7.3794\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2750 - mae: 7.2750\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2694 - mae: 7.2694\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2638 - mae: 7.2638\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2581 - mae: 7.2581\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2525 - mae: 7.2525\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2469 - mae: 7.2469\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2412 - mae: 7.2412\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2356 - mae: 7.2356\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2300 - mae: 7.2300\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2244 - mae: 7.2244\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2188 - mae: 7.2188\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2131 - mae: 7.2131\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2075 - mae: 7.2075\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2019 - mae: 7.2019\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1962 - mae: 7.1962\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1906 - mae: 7.1906\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1850 - mae: 7.1850\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1794 - mae: 7.1794\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1737 - mae: 7.1737\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1681 - mae: 7.1681\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1625 - mae: 7.1625\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1569 - mae: 7.1569\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1512 - mae: 7.1512\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1456 - mae: 7.1456\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1400 - mae: 7.1400\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1344 - mae: 7.1344\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1287 - mae: 7.1287\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1231 - mae: 7.1231\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1175 - mae: 7.1175\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1119 - mae: 7.1119\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1062 - mae: 7.1062\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1006 - mae: 7.1006\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0950 - mae: 7.0950\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0894 - mae: 7.0894\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0838 - mae: 7.0838\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0781 - mae: 7.0781\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.0725 - mae: 7.0725\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0669 - mae: 7.0669\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0613 - mae: 7.0613\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0556 - mae: 7.0556\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0500 - mae: 7.0500\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0444 - mae: 7.0444\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0388 - mae: 7.0388\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0331 - mae: 7.0331\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.0275 - mae: 7.0275\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0219 - mae: 7.0219\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0163 - mae: 7.0163\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0106 - mae: 7.0106\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0050 - mae: 7.0050\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9994 - mae: 6.9994\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9938 - mae: 6.9938\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9881 - mae: 6.9881\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9825 - mae: 6.9825\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9769 - mae: 6.9769\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9713 - mae: 6.9713\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9656 - mae: 6.9656\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9600 - mae: 6.9600\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9544 - mae: 6.9544\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9488 - mae: 6.9488\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9431 - mae: 6.9431\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9375 - mae: 6.9375\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9319 - mae: 6.9319\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9263 - mae: 6.9263\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9206 - mae: 6.9206\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9150 - mae: 6.9150\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9094 - mae: 6.9094\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9038 - mae: 6.9038\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8981 - mae: 6.8981\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.8925 - mae: 6.8925\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.8869 - mae: 6.8869\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6c40cde0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtoYixxyXDbY",
        "outputId": "b9311abc-c92d-4a1f-fc1a-e8591d9d1b44"
      },
      "source": [
        "# Remind ourselves of the data\n",
        "X, y"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWIYqTGiXWXt",
        "outputId": "d383090a-1632-40d1-82f9-ecf6696761a7"
      },
      "source": [
        "# Predict using trained model\n",
        "model.predict([17.0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.739855]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBvXMf97Xb2X",
        "outputId": "cf308fce-b6b3-40ea-b41b-a8b31a4e19d5"
      },
      "source": [
        "# Let's see if we can make another change to improve the model\n",
        "\n",
        "# 1. create the model (with an extra hidden layer with 100 hidden units)\n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(100, activation=None),\n",
        "        tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2.Compile the model\n",
        "model.compile(loss = tf.keras.losses.mae,\n",
        "              optimizer = tf.keras.optimizers.Adam(lr=0.01),\n",
        "              metrics = [\"mae\"])\n",
        "\n",
        "# 3.Fit the model\n",
        "model.fit(X, y, epochs=100)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 12.0109 - mae: 12.0109\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.0827 - mae: 11.0827\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.1377 - mae: 10.1377\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 9.1687 - mae: 9.1687\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.1666 - mae: 8.1666\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.1234 - mae: 7.1234\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0477 - mae: 7.0477\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.4551 - mae: 7.4551\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.7955 - mae: 7.7955\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.8032 - mae: 7.8032\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.5199 - mae: 7.5199\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1109 - mae: 7.1109\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.7677 - mae: 6.7677\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.4015 - mae: 6.4015\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.2357 - mae: 6.2357\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.2423 - mae: 6.2423\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.3558 - mae: 6.3558\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.3170 - mae: 6.3170\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.1485 - mae: 6.1485\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.8645 - mae: 5.8645\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.6410 - mae: 5.6410\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4964 - mae: 5.4964\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4790 - mae: 5.4790\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.4653 - mae: 5.4653\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.3918 - mae: 5.3918\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.2633 - mae: 5.2633\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.0845 - mae: 5.0845\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.8603 - mae: 4.8603\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.5949 - mae: 4.5949\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.4549 - mae: 4.4549\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.3419 - mae: 4.3419\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.2469 - mae: 4.2469\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9892 - mae: 3.9892\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7639 - mae: 3.7639\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.5838 - mae: 3.5838\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.4578 - mae: 3.4578\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.2638 - mae: 3.2638\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0042 - mae: 3.0042\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.6811 - mae: 2.6811\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4239 - mae: 2.4239\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3193 - mae: 2.3193\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.0514 - mae: 2.0514\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5789 - mae: 1.5789\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2803 - mae: 1.2803\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0003 - mae: 1.0003\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6312 - mae: 0.6312\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3519 - mae: 0.3519\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3731 - mae: 0.3731\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5498 - mae: 0.5498\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7918 - mae: 0.7918\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8574 - mae: 0.8574\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9625 - mae: 0.9625\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9383 - mae: 0.9383\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9712 - mae: 0.9712\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8290 - mae: 0.8290\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7937 - mae: 0.7937\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6822 - mae: 0.6822\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3600 - mae: 0.3600\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3560 - mae: 0.3560\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4129 - mae: 0.4129\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2622 - mae: 0.2622\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5552 - mae: 0.5552\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6130 - mae: 0.6130\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4665 - mae: 0.4665\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5549 - mae: 0.5549\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5040 - mae: 0.5040\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3059 - mae: 0.3059\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3180 - mae: 0.3180\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1289 - mae: 0.1289\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3193 - mae: 0.3193\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4343 - mae: 0.4343\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.3293 - mae: 0.3293\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5476 - mae: 0.5476\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6087 - mae: 0.6087\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3411 - mae: 0.3411\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4043 - mae: 0.4043\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6183 - mae: 0.6183\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4809 - mae: 0.4809\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0982 - mae: 0.0982\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2504 - mae: 0.2504\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1929 - mae: 0.1929\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1561 - mae: 0.1561\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0545 - mae: 0.0545\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3572 - mae: 0.3572\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3705 - mae: 0.3705\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0835 - mae: 0.0835\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3945 - mae: 0.3945\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4196 - mae: 0.4196\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1171 - mae: 0.1171\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4845 - mae: 0.4845\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6957 - mae: 0.6957\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5739 - mae: 0.5739\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1783 - mae: 0.1783\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4492 - mae: 0.4492\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6536 - mae: 0.6536\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5370 - mae: 0.5370\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1539 - mae: 0.1539\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4828 - mae: 0.4828\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6920 - mae: 0.6920\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5813 - mae: 0.5813\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6c40be80d0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9Se5H50Y2vc",
        "outputId": "d0ba25a9-01cd-497d-d07d-23d54869b2de"
      },
      "source": [
        "# let's remind ourselves of the data\n",
        "X, y"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_njPiXFZGZr",
        "outputId": "237c8c3d-9816-41a8-8c26-78ac5e9315a3"
      },
      "source": [
        "# predict on trained model\n",
        "model.predict([17.0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[26.48575]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJjGArqfZKhP"
      },
      "source": [
        "* So, eventhough loss and mae are lower this time, prediction is worse than the previous model. This implies that the model is overfitting, i.e it's learning the training data too well but not able to generalize on new unseen data.\n",
        "\n",
        "* In above case, changing the optimizer to `Adam` with `lr=0.01` has given best results so far.\n",
        "\n",
        "* Common ways to improve a deep model:\n",
        "  * Adding layers\n",
        "  * Increase the number of hidden units\n",
        "  * Change the activation functions\n",
        "  * Change the optimization function\n",
        "  * Change the learning rate\n",
        "  * Fitting on more data\n",
        "  * Fitting for longer\n",
        "\n",
        "* `learning_rate` is most important important hyperparameter for neural networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PP3qfT5iZWd8"
      },
      "source": [
        "## Evaluating a model\n",
        "\n",
        "In practice, a typical workflow you'll go throught when building neural networks is:\n",
        "\n",
        "```\n",
        "Build a model -> fit it -> evaluate it -> tweak a model -> fit it -> evaluate it -> tweak a model -> fit it -> evaluate it...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpYeMke3cahr"
      },
      "source": [
        "When it comes to evaluation..there are 3 words to memorize:\n",
        "\n",
        "> \"Visualize, visualize, visualize\"\n",
        "\n",
        "It's a good idea to visualize:\n",
        "* The data - what data are we working with? what does it look like?\n",
        "* The model itself - what does our model look like?\n",
        "* The training of a model - how does a model perform while it learns?\n",
        "* The predictions of the model - how do the predictions of a model line up against the ground truth (the original labels)? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLQYT9SQehVK",
        "outputId": "6c3a89df-3be0-4949-fcaf-dd7bf0405961"
      },
      "source": [
        "# Make a bigger dataset\n",
        "X = tf.range(-100, 100, 4)\n",
        "X"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "         76,   80,   84,   88,   92,   96], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yw_GBXVee4Kr",
        "outputId": "4c2349e8-d4c1-4486-fbfb-d2881234f428"
      },
      "source": [
        "# Make labels for the dataset\n",
        "y = X+10  # pattern that the model has to learn\n",
        "y"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "0qv-9IjIfA4E",
        "outputId": "d0f671c3-18f3-447b-cc4e-601b9fbcd3f6"
      },
      "source": [
        "# Visualize the data\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(X, y)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f6c40b40850>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbNBr52bfOqa"
      },
      "source": [
        "### The 3 sets...\n",
        "\n",
        "* **Training set** - the model learns from this data, which is typically 70-80% of the total data you have available.\n",
        "* **Validation set** - the model gets tuned on this data, which is typically 10-15% of the data available.\n",
        "* **Test set** - the model gets evaluated on this data to test what it has learned, this set is typically 10-15% of the total data available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFOQT7wXgxET",
        "outputId": "73a8c9aa-9657-40ab-bb93-0e63e3a6d5dc"
      },
      "source": [
        "# Check the length of how many samples we have\n",
        "len(X)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlKhDXiWhMNA",
        "outputId": "b325ac05-aaf9-484a-ac01-6c80aef0126b"
      },
      "source": [
        "# Split the data into train and test set\n",
        "X_train = X[:40] # first 40 are training samples (80% of the data)\n",
        "y_train = y[:40]\n",
        "\n",
        "X_test = X[40:] # last 10 are testing smaples (20% of the data)\n",
        "y_test = y[40:]\n",
        "\n",
        "len(X_train), len(X_test), len(y_train), len(y_test)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 10, 40, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4xLWOd4h4PX"
      },
      "source": [
        "### Visualizing the data\n",
        "\n",
        "Now we've got our data in training and test sets...let's visualize it again!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "ikGk8KWSiVbM",
        "outputId": "d0469bd7-006a-418e-903f-2cdb05477362"
      },
      "source": [
        "plt.figure(figsize=(10,7))\n",
        "\n",
        "# plot training data in blue\n",
        "plt.scatter(X_train, y_train, c=\"b\", label=\"Training Data\")\n",
        "# plot test data in green\n",
        "plt.scatter(X_test, y_test, c=\"r\", label=\"Testing Data\")\n",
        "# Show a legend\n",
        "plt.legend();"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AJO_NHU-cyJ"
      },
      "source": [
        "# Let's have a look at how to build a neural network for our data\n",
        "\n",
        "# 1. Create a model\n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "#2. Compile the model\n",
        "model.compile(loss = tf.keras.losses.mae,\n",
        "              optimizer = tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "#3. Fit the model\n",
        "# model.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85lxCUCoAE8L"
      },
      "source": [
        "### Visualizing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p9yohELANFr"
      },
      "source": [
        "# model.summary()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEUq5lCVAotT"
      },
      "source": [
        "# Let's create a model which builds automatically by defining the input shape argument in the first layer\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model\n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(1, input_shape=[1])  # we are passing one number to predict one number                    \n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss = tf.keras.losses.mae,\n",
        "              optimizer = tf.keras.optimizers.SGD(),\n",
        "              metrics = [\"mae\"])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbWo_DxjBgPF",
        "outputId": "e650a8c2-e483-447c-e5ee-391ed4ef9c00"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 1)                 2         \n",
            "=================================================================\n",
            "Total params: 2\n",
            "Trainable params: 2\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sp9tkwALBy33"
      },
      "source": [
        "* **Total params** - total number of parameters in the model.\n",
        "* **Trainable params** = these are the parameters (patterns) the model can update as it trains.\n",
        "* **Non trainable params** - these parameters aren't updated during training (this is typical when you bring in already learnt patterns or parameters from other models during **transfer learning**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWqxz_AtBijE",
        "outputId": "57574169-4875-4f57-d489-bb6eca16ef81"
      },
      "source": [
        "# Let's fit our model to the training data\n",
        "model.fit(X_train, y_train, epochs=100, verbose=1)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.9024 - mae: 15.9024\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.2837 - mae: 11.2837\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.1074 - mae: 11.1074\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 9.2991 - mae: 9.2991\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.1677 - mae: 10.1677\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.4303 - mae: 9.4303\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.5704 - mae: 8.5704\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.0442 - mae: 9.0442\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 18.7517 - mae: 18.7517\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.1142 - mae: 10.1142\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.3980 - mae: 8.3980\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.6639 - mae: 10.6639\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.7977 - mae: 9.7977\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.0103 - mae: 16.0103\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 11.4068 - mae: 11.4068\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.5393 - mae: 8.5393\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.6348 - mae: 13.6348\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.4629 - mae: 11.4629\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 17.9148 - mae: 17.9148\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.0494 - mae: 15.0494\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.0216 - mae: 11.0216\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.1558 - mae: 8.1558\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.5138 - mae: 9.5138\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6617 - mae: 7.6617\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.1859 - mae: 13.1859\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.4211 - mae: 16.4211\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.1660 - mae: 13.1660\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.2559 - mae: 14.2559\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.0670 - mae: 10.0670\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.3409 - mae: 16.3409\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.6444 - mae: 23.6444\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.6215 - mae: 7.6215\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.3221 - mae: 9.3221\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.7313 - mae: 13.7313\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.1276 - mae: 11.1276\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.3222 - mae: 13.3222\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.4763 - mae: 9.4763\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.1381 - mae: 10.1381\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.1793 - mae: 10.1793\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.9137 - mae: 10.9137\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.9063 - mae: 7.9063\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.0914 - mae: 10.0914\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.7006 - mae: 8.7006\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.2047 - mae: 12.2047\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.7970 - mae: 13.7970\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.4687 - mae: 8.4687\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.1330 - mae: 9.1330\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.6190 - mae: 10.6190\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.7503 - mae: 7.7503\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.5407 - mae: 9.5407\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.1584 - mae: 9.1584\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.3630 - mae: 16.3630\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.1299 - mae: 14.1299\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 21.1247 - mae: 21.1247\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.3961 - mae: 16.3961\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.9806 - mae: 9.9806\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.9606 - mae: 9.9606\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9.2209 - mae: 9.2209\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.4239 - mae: 8.4239\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.4869 - mae: 9.4869\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.4355 - mae: 11.4355\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.6887 - mae: 11.6887\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.0838 - mae: 7.0838\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 16.9675 - mae: 16.9675\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 12.4599 - mae: 12.4599\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.0184 - mae: 13.0184\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.0600 - mae: 8.0600\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.1888 - mae: 10.1888\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.3633 - mae: 12.3633\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.0516 - mae: 9.0516\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.0378 - mae: 10.0378\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.0516 - mae: 10.0516\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.6151 - mae: 12.6151\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.3819 - mae: 10.3819\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 9.7229 - mae: 9.7229\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.2252 - mae: 11.2252\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.3642 - mae: 8.3642\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.1274 - mae: 9.1274\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 19.5039 - mae: 19.5039\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.8945 - mae: 14.8945\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.0034 - mae: 9.0034\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.0206 - mae: 13.0206\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.9299 - mae: 7.9299\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6872 - mae: 7.6872\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.0328 - mae: 10.0328\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.2433 - mae: 9.2433\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.0209 - mae: 12.0209\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.6389 - mae: 10.6389\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.2667 - mae: 7.2667\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.7786 - mae: 12.7786\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.3481 - mae: 7.3481\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.7175 - mae: 7.7175\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.1263 - mae: 7.1263\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.6190 - mae: 12.6190\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 10.0912 - mae: 10.0912\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.3558 - mae: 9.3558\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.6834 - mae: 12.6834\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.6762 - mae: 8.6762\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.4693 - mae: 9.4693\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.7067 - mae: 8.7067\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6c40a67750>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP-RE9U3ZSs2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}